{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- The Keras functional API is a way to create models that is more flexible than the `tf.keras.Sequential` API. \n",
    "- The functional API can handle models with **non-linear topology**, models with **shared layers**, and models with **multiple inputs or outputs**.\n",
    "- The main idea that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build **graphs of layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,))\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation='relu')\n",
    "X = dense(inputs)\n",
    "X = layers.Dense(64, activation='relu')(X)\n",
    "outputs = layers.Dense(10)(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At this point, you can create a `Model` by specifying its inputs in the graph of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation, and inference\n",
    "- Training, evaluation, and inference work exactly in the same way for models built using the functional API as for `Sequential` models.\n",
    "- Here, load the MNIST image data, reshape it into vectors, fit the model on the data (while monitoring performance on a validation split), then evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "X_test = X_test.reshape(10000, 784).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.3431 - accuracy: 0.9010 - val_loss: 0.1894 - val_accuracy: 0.9442\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 3s 66us/sample - loss: 0.1595 - accuracy: 0.9524 - val_loss: 0.1385 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13393157647661866, 0.9589]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and serialize\n",
    "- Saving the model and serialization work the same way for models built using the functional API as they do for `Sequential` models. \n",
    "- The standard way to save a functional model is to call `model.save()` to save the entire model as a single file.\n",
    "    - You can later recreate the same model from this file, even if the code that built the model is no longer available.\n",
    "    - This saved file includes the:\n",
    "        - model architecture\n",
    "        - model weight values (that were learned during training)\n",
    "        - model training config, if any (as passed to `compile`)\n",
    "        - optimizer and its state, if any (to restart training where you left off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"path_to_save_the_model\")\n",
    "# model = keras.models.load_model(\"path_to_save_the_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the same graph of layers to define multiple models\n",
    "- In the functional API, models are created by specifying their inputs and outputs in a graph of layers. \n",
    "    - That means that a single graph of layers can be used to generate multiple models.\n",
    "- In the example below, you use the same stack of layers to instantiate two models: an encoder model that turns image inputs into 16-dimensional vectors, and an end-to-end autoencoder model for training.\n",
    "    - Here, the decoding architecture is strictly symmetrical to the encoding architecture, so the output shape is the same as the input shape `(28, 28, 1)`.\n",
    "    - The reverse of a `Conv2D` layer is a `Conv2DTranspose` layer, and the reverse of a `MaxPooling2D` layer is an `UpSampling2D` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "X = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "X = layers.Conv2D(32, 3, activation='relu')(X)\n",
    "X = layers.MaxPooling2D(3)(X)\n",
    "X = layers.Conv2D(32, 3, activation='relu')(X)\n",
    "X = layers.Conv2D(16, 3, activation='relu')(X)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(X)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "X = layers.Conv2DTranspose(16, 3, activation=\"relu\")(X)\n",
    "X = layers.Conv2DTranspose(32, 3, activation=\"relu\")(X)\n",
    "X = layers.UpSampling2D(3)(X)\n",
    "X = layers.Conv2DTranspose(16, 3, activation=\"relu\")(X)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(X)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All models are callable, just like layers\n",
    "- You can treat any model as if it were a layer by invoking it on an `Input` or on the output of another layer. \n",
    "- By calling a model you aren't just reusing the architecture of the model, you're also reusing its weights.\n",
    "- To see this in action, here's a different take on the autoencoder example that creates an encoder model, a decoder model, and chain them in two calls to obtain the autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "X = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "X = layers.Conv2D(32, 3, activation=\"relu\")(X)\n",
    "X = layers.MaxPooling2D(3)(X)\n",
    "X = layers.Conv2D(32, 3, activation=\"relu\")(X)\n",
    "X = layers.Conv2D(16, 3, activation=\"relu\")(X)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(X)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "X = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "X = layers.Conv2DTranspose(16, 3, activation=\"relu\")(X)\n",
    "X = layers.Conv2DTranspose(32, 3, activation=\"relu\")(X)\n",
    "X = layers.UpSampling2D(3)(X)\n",
    "X = layers.Conv2DTranspose(16, 3, activation=\"relu\")(X)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(X)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, the model can be nested: a model can contain sub-models (since a model is just like a layer). \n",
    "- A common use case for model nesting is **ensembling**. \n",
    "- For example, here's how to ensemble a set of models into a single model that averages their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate complex graph topologies\n",
    "## Models with multiple inputs and outputs\n",
    "- The functional API makes it easy to manipulate multiple inputs and outputs, which cannot be handled with the `Sequential` API.\n",
    "- For example, if you're building a system for ranking custom issue tickets by priority and routing them to the correct department, then the model will have three inputs:\n",
    "    - The title of the ticket (text input)\n",
    "    - The text body of the ticket (text input)\n",
    "    - Any tags added by the user (categorical input)\n",
    "- The model will have two outputs:\n",
    "    - The priority score between 0 and 1 (scaler sigmoid output)\n",
    "    - The department that should handle the ticket (sigmoid output over the set of departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12 \n",
    "num_words = 10000 \n",
    "num_departments = 4\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name='title')\n",
    "body_input = keras.Input(shape=(None,), name='body')\n",
    "tags_input = keras.Input(shape=(num_tags,), name='tags')\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "X = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name='priority')(X)\n",
    "\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name='department')(X)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, 'multi_input_and_output.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When compiling the model, you can assign different losses to each output.\n",
    "- You can even assign different weights to each loss to modulate their contribution to the total training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=[keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
    "             loss_weights=[1.0, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the output layers have different names, you could also specify the loss like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss={\"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   \"department\": keras.losses.CategoricalCrossentropy(from_logits=True)},\n",
    "             loss_weights=[1.0, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model by passing lists of Numpy arrays of inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples\n",
      "Epoch 1/2\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 1.2756 - priority_loss: 0.7051 - department_loss: 2.8525\n",
      "Epoch 2/2\n",
      "1280/1280 [==============================] - 7s 5ms/sample - loss: 1.2714 - priority_loss: 0.7047 - department_loss: 2.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffde13b1390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'title': title_data, 'body': body_data, 'tags': tags_data},\n",
    "    {'priority': priority_targets, 'department': dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy ResNet model\n",
    "- In addition to models with multiple inputs and outputs, the functional API makes it easy to manipulate **non-linear connectivity topologies** - these are models with layers that are not connected sequentially.\n",
    "- A common use case for this is **residual connections**. \n",
    "- Let's build a toy ResNet model for CIFAR10 to demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 9, 9, 64)     0           conv2d_11[0][0]                  \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_13[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          16640       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
    "X = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "X = layers.Conv2D(64, 3, activation='relu')(X)\n",
    "block_1_output = layers.MaxPool2D(3)(X)\n",
    "\n",
    "X = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "X = layers.Conv2D(64, 3, activation='relu', padding='same')(X)\n",
    "block_2_output = layers.add([X, block_1_output])\n",
    "\n",
    "X = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "X = layers.Conv2D(64, 3, activation='relu', padding='same')(X)\n",
    "block_3_output = layers.add([X, block_2_output])\n",
    "\n",
    "X = layers.Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "X = layers.GlobalAveragePooling2D()(X)\n",
    "X = layers.Dense(256, activation='relu')(X)\n",
    "X = layers.Dropout(0.5)(X)\n",
    "outputs = layers.Dense(10)(X)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='toy_resnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, 'mini_resnet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 2.3110 - accuracy: 0.1112 - val_loss: 2.2978 - val_accuracy: 0.0700\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - 2s 3ms/sample - loss: 2.3036 - accuracy: 0.1213 - val_loss: 2.2598 - val_accuracy: 0.1350\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - 2s 3ms/sample - loss: 2.3061 - accuracy: 0.1600 - val_loss: 2.2263 - val_accuracy: 0.1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffdae094710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[:1000], y_train[:1000], batch_size=64, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared layers\n",
    "- Shared layers are layer instances that are reused multiple times in a same model - they learn features that correspond to multiple paths in the graph-of-layers.\n",
    "- Shared layers are often used to encode inputs from similar spaces (say, two different pieces of text that feature similar vocabulary). \n",
    "    - They enable sharing of information across these different inputs, and they make it possible to train such a model on less data. \n",
    "    - If a given word is seen in one of the inputs, that will benefit the processing of all inputs that pass through the shared layer.\n",
    "- To share a layer in the functional API, call the same layer instance multiple times. \n",
    "- For instance, here's an `Embedding` layer shared across two different text inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_b = keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and reuse nodes in the graph of layers\n",
    "- Because the graph of layers you are manipulating is a static data structure, it can be accessed and inspected.\n",
    "    - This is how you are able to plot functional models as images.\n",
    "    - This also means that you can access the activations of intermediate layers (\"nodes\" in the graph) and reuse them elsewhere, which is very useful for something like feature extraction.\n",
    "- Let's look at an example of a VGG19 model with weights pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = tf.keras.applications.VGG19()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's obtain the intermediate activations of the model by querying the graph data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_8:0' shape=(None, 224, 224, 3) dtype=float32>,\n",
       " <tf.Tensor 'block1_conv1/Identity:0' shape=(None, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'block1_conv2/Identity:0' shape=(None, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'block1_pool/Identity:0' shape=(None, 112, 112, 64) dtype=float32>,\n",
       " <tf.Tensor 'block2_conv1/Identity:0' shape=(None, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'block2_conv2/Identity:0' shape=(None, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'block2_pool/Identity:0' shape=(None, 56, 56, 128) dtype=float32>,\n",
       " <tf.Tensor 'block3_conv1/Identity:0' shape=(None, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'block3_conv2/Identity:0' shape=(None, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'block3_conv3/Identity:0' shape=(None, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'block3_conv4/Identity:0' shape=(None, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'block3_pool/Identity:0' shape=(None, 28, 28, 256) dtype=float32>,\n",
       " <tf.Tensor 'block4_conv1/Identity:0' shape=(None, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'block4_conv2/Identity:0' shape=(None, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'block4_conv3/Identity:0' shape=(None, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'block4_conv4/Identity:0' shape=(None, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'block4_pool/Identity:0' shape=(None, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'block5_conv1/Identity:0' shape=(None, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'block5_conv2/Identity:0' shape=(None, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'block5_conv3/Identity:0' shape=(None, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'block5_conv4/Identity:0' shape=(None, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'block5_pool/Identity:0' shape=(None, 7, 7, 512) dtype=float32>,\n",
       " <tf.Tensor 'flatten/Identity:0' shape=(None, 25088) dtype=float32>,\n",
       " <tf.Tensor 'fc1/Identity:0' shape=(None, 4096) dtype=float32>,\n",
       " <tf.Tensor 'fc2/Identity:0' shape=(None, 4096) dtype=float32>,\n",
       " <tf.Tensor 'predictions/Identity:0' shape=(None, 1000) dtype=float32>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = [layer.output for layer in vgg19.layers]\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's use these features to create a new feature-extraction model that returns the values of the intermediate layer activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model = keras.Model(inputs=vgg19.input, outputs=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.random((1, 244, 244, 3)).astype('float32')\n",
    "extracted_features = feature_extraction_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=18440, shape=(1, 244, 244, 3), dtype=float32, numpy=\n",
       " array([[[[0.01910218, 0.23959348, 0.03273841],\n",
       "          [0.59789544, 0.51862437, 0.4374817 ],\n",
       "          [0.5622721 , 0.785809  , 0.71979773],\n",
       "          ...,\n",
       "          [0.89344704, 0.96663594, 0.03261928],\n",
       "          [0.12798543, 0.54168135, 0.07553687],\n",
       "          [0.00182972, 0.4259034 , 0.5178315 ]],\n",
       " \n",
       "         [[0.47503135, 0.46647358, 0.6928288 ],\n",
       "          [0.66985554, 0.9231054 , 0.58157104],\n",
       "          [0.54263586, 0.32283202, 0.36899155],\n",
       "          ...,\n",
       "          [0.31769887, 0.18798204, 0.8339225 ],\n",
       "          [0.3950599 , 0.57703817, 0.71434957],\n",
       "          [0.89083767, 0.6465756 , 0.38688296]],\n",
       " \n",
       "         [[0.70425844, 0.66526914, 0.6328171 ],\n",
       "          [0.03174131, 0.24581972, 0.86410886],\n",
       "          [0.4923992 , 0.5273285 , 0.21161635],\n",
       "          ...,\n",
       "          [0.32229134, 0.5500966 , 0.42561767],\n",
       "          [0.3449951 , 0.62926257, 0.2221869 ],\n",
       "          [0.50959224, 0.8059536 , 0.84928644]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.3918802 , 0.6677475 , 0.5499891 ],\n",
       "          [0.92329824, 0.67543185, 0.6435745 ],\n",
       "          [0.13937324, 0.67910486, 0.7315009 ],\n",
       "          ...,\n",
       "          [0.11777061, 0.82628626, 0.40244484],\n",
       "          [0.7787075 , 0.0279324 , 0.17110522],\n",
       "          [0.99054927, 0.9332571 , 0.12843247]],\n",
       " \n",
       "         [[0.23101737, 0.5881824 , 0.5202079 ],\n",
       "          [0.8718762 , 0.11921873, 0.9999724 ],\n",
       "          [0.21696182, 0.5003461 , 0.05364279],\n",
       "          ...,\n",
       "          [0.78954685, 0.2801398 , 0.35843834],\n",
       "          [0.5865056 , 0.604406  , 0.37796164],\n",
       "          [0.88501245, 0.24987957, 0.52908933]],\n",
       " \n",
       "         [[0.9918589 , 0.72855365, 0.13265681],\n",
       "          [0.30215403, 0.23085871, 0.72043395],\n",
       "          [0.54547334, 0.36919883, 0.3344805 ],\n",
       "          ...,\n",
       "          [0.90117127, 0.11060383, 0.23930393],\n",
       "          [0.13261932, 0.9549889 , 0.23728496],\n",
       "          [0.9662059 , 0.3550577 , 0.31469032]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18445, shape=(1, 244, 244, 64), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.09145825, 0.        , ..., 0.5042441 ,\n",
       "           0.19459817, 0.        ],\n",
       "          [0.        , 0.26340267, 0.26273423, ..., 0.27022558,\n",
       "           1.0535189 , 0.58622324],\n",
       "          [0.        , 0.37393832, 0.51644313, ..., 0.17255789,\n",
       "           1.5191354 , 1.2724729 ],\n",
       "          ...,\n",
       "          [0.        , 0.32385355, 0.4535572 , ..., 0.4113155 ,\n",
       "           1.3898804 , 1.1164598 ],\n",
       "          [0.        , 0.25617656, 0.3480754 , ..., 0.2726394 ,\n",
       "           1.3452151 , 0.91702443],\n",
       "          [0.38543656, 0.2564793 , 0.42550635, ..., 0.65986156,\n",
       "           1.6554928 , 1.3549535 ]],\n",
       " \n",
       "         [[0.        , 0.11350228, 0.02547503, ..., 0.28277045,\n",
       "           0.01633471, 0.        ],\n",
       "          [0.61562765, 0.2990663 , 0.40660655, ..., 0.        ,\n",
       "           0.67990136, 0.85282755],\n",
       "          [1.540884  , 0.39174768, 0.4834016 , ..., 0.        ,\n",
       "           0.3998086 , 0.7634784 ],\n",
       "          ...,\n",
       "          [0.7993462 , 0.25800443, 0.35647163, ..., 0.        ,\n",
       "           0.4210159 , 0.5505413 ],\n",
       "          [0.28796893, 0.26125595, 0.35295206, ..., 0.        ,\n",
       "           0.49742258, 0.4560178 ],\n",
       "          [1.3693492 , 0.3997126 , 0.7651702 , ..., 0.4186266 ,\n",
       "           1.9476329 , 2.0685992 ]],\n",
       " \n",
       "         [[0.        , 0.08658564, 0.02854053, ..., 0.15933228,\n",
       "           0.        , 0.01045528],\n",
       "          [1.1247895 , 0.2067051 , 0.2854967 , ..., 0.        ,\n",
       "           0.55462205, 0.669402  ],\n",
       "          [1.0158517 , 0.37239853, 0.3830868 , ..., 0.        ,\n",
       "           0.5817772 , 0.56356514],\n",
       "          ...,\n",
       "          [0.42859647, 0.11824568, 0.1057438 , ..., 0.        ,\n",
       "           0.43898052, 0.40673804],\n",
       "          [0.29181066, 0.16441756, 0.15340988, ..., 0.        ,\n",
       "           0.04657671, 0.06860059],\n",
       "          [2.0822232 , 0.41506067, 0.71492976, ..., 0.23482025,\n",
       "           1.5953478 , 1.9360585 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.16130656, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [1.2140814 , 0.39374626, 0.51356673, ..., 0.        ,\n",
       "           1.0870053 , 1.3433962 ],\n",
       "          [0.55206406, 0.2933046 , 0.30039567, ..., 0.        ,\n",
       "           0.47441465, 0.58471894],\n",
       "          ...,\n",
       "          [1.3750182 , 0.42199776, 0.38702616, ..., 0.        ,\n",
       "           0.7966447 , 0.88559884],\n",
       "          [0.38310668, 0.40680522, 0.15066941, ..., 0.        ,\n",
       "           0.05152693, 0.01239932],\n",
       "          [1.8005245 , 0.59712446, 0.6259759 , ..., 0.25410998,\n",
       "           1.4881189 , 1.7200234 ]],\n",
       " \n",
       "         [[0.        , 0.19778535, 0.        , ..., 0.06306076,\n",
       "           0.        , 0.        ],\n",
       "          [1.46871   , 0.36446398, 0.4133951 , ..., 0.        ,\n",
       "           0.58630794, 0.88250935],\n",
       "          [0.9615226 , 0.18959212, 0.17182085, ..., 0.        ,\n",
       "           0.02324522, 0.15070108],\n",
       "          ...,\n",
       "          [1.074053  , 0.4410183 , 0.47248182, ..., 0.        ,\n",
       "           0.889185  , 1.0032316 ],\n",
       "          [0.42468378, 0.59626573, 0.32630855, ..., 0.        ,\n",
       "           0.2720391 , 0.2718922 ],\n",
       "          [1.8940115 , 0.7003674 , 0.7484316 , ..., 0.27832836,\n",
       "           1.5499829 , 1.7664745 ]],\n",
       " \n",
       "         [[0.9146942 , 0.191383  , 0.10367644, ..., 0.49714762,\n",
       "           0.        , 0.22746076],\n",
       "          [2.168269  , 0.30252978, 0.41601253, ..., 0.29924977,\n",
       "           0.40674248, 1.0839591 ],\n",
       "          [1.5207355 , 0.09930295, 0.19931482, ..., 0.27077955,\n",
       "           0.        , 0.52119464],\n",
       "          ...,\n",
       "          [2.1525745 , 0.27315375, 0.35191616, ..., 0.19893253,\n",
       "           0.1002827 , 0.7469259 ],\n",
       "          [1.6984429 , 0.4290052 , 0.31526342, ..., 0.21891302,\n",
       "           0.        , 0.51862055],\n",
       "          [2.5054815 , 0.44285524, 0.6041219 , ..., 0.5846165 ,\n",
       "           0.9794588 , 1.5549178 ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18450, shape=(1, 244, 244, 64), dtype=float32, numpy=\n",
       " array([[[[5.9681354e+00, 1.1270077e+00, 7.8385508e-01, ...,\n",
       "           9.0736377e-01, 2.7227054e+00, 1.8846335e+00],\n",
       "          [1.4246895e+00, 1.2375951e+00, 1.8350476e+00, ...,\n",
       "           1.4842101e+00, 2.0655055e+00, 1.8513854e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 1.4392049e+00, ...,\n",
       "           1.1756662e+00, 1.2191228e+00, 1.2528231e+00],\n",
       "          ...,\n",
       "          [3.5382217e-01, 5.8266407e-01, 1.7317624e+00, ...,\n",
       "           1.0800780e+00, 1.4236546e+00, 1.6029925e+00],\n",
       "          [8.8994199e-01, 0.0000000e+00, 1.1706257e+00, ...,\n",
       "           8.6409694e-01, 1.0336137e+00, 1.9084365e+00],\n",
       "          [0.0000000e+00, 4.1164625e-01, 5.8264774e-01, ...,\n",
       "           8.6057711e-01, 0.0000000e+00, 8.3097702e-01]],\n",
       " \n",
       "         [[1.6261542e+00, 6.0604835e-01, 1.7935284e+00, ...,\n",
       "           1.8296520e+00, 2.8501279e+00, 1.3985038e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 3.5743589e+00, ...,\n",
       "           1.8788213e+00, 2.7676468e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 3.0363927e+00, ...,\n",
       "           1.0722216e+00, 2.0295420e+00, 7.1352184e-02],\n",
       "          ...,\n",
       "          [1.1781147e-01, 1.7762393e-02, 3.2168677e+00, ...,\n",
       "           2.0879819e+00, 4.2152991e+00, 3.2061249e-01],\n",
       "          [3.9017576e-01, 0.0000000e+00, 2.6028910e+00, ...,\n",
       "           1.6459450e+00, 6.9295034e+00, 3.8995409e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 1.3620107e+00, ...,\n",
       "           1.4090644e+00, 1.7522539e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 1.5547106e+00, ...,\n",
       "           1.3427106e+00, 1.9953856e+00, 4.2780429e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 3.0604427e+00, ...,\n",
       "           1.5361176e+00, 2.0001135e+00, 6.0315186e-01],\n",
       "          [2.7529504e+00, 7.8413975e-01, 2.7286530e+00, ...,\n",
       "           1.4049217e+00, 0.0000000e+00, 8.1789809e-01],\n",
       "          ...,\n",
       "          [1.2361240e+00, 1.8599243e+00, 3.3600266e+00, ...,\n",
       "           2.7529886e+00, 0.0000000e+00, 7.1988696e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.6943760e+00, ...,\n",
       "           1.5928129e+00, 3.9677269e+00, 7.7439159e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 1.1081111e+00, ...,\n",
       "           1.1509973e+00, 2.9876046e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[8.9787728e-01, 0.0000000e+00, 2.6647358e+00, ...,\n",
       "           1.3710327e+00, 3.9117970e+00, 4.4239050e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 4.8225460e+00, ...,\n",
       "           2.3167248e+00, 4.4095421e+00, 3.6564535e-01],\n",
       "          [5.5056792e-01, 0.0000000e+00, 4.2629361e+00, ...,\n",
       "           1.9352998e+00, 2.2080176e-02, 3.4040582e-01],\n",
       "          ...,\n",
       "          [6.5504313e-03, 0.0000000e+00, 5.8882117e+00, ...,\n",
       "           2.0538330e+00, 1.4063123e-01, 7.3979193e-01],\n",
       "          [2.7690399e+00, 3.2128391e-01, 6.3489299e+00, ...,\n",
       "           1.6235061e+00, 1.1622610e+00, 8.7781030e-01],\n",
       "          [0.0000000e+00, 5.1345867e-01, 4.3101077e+00, ...,\n",
       "           1.2556760e+00, 1.7642313e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 2.8301628e+00, ...,\n",
       "           1.2576704e+00, 2.2576809e+00, 8.1818825e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 4.5836415e+00, ...,\n",
       "           2.0397882e+00, 4.0656357e+00, 1.2229824e+00],\n",
       "          [1.6730692e+00, 0.0000000e+00, 3.4298906e+00, ...,\n",
       "           1.8649101e+00, 7.1774417e-01, 1.5818586e+00],\n",
       "          ...,\n",
       "          [9.2009598e-01, 0.0000000e+00, 5.8775458e+00, ...,\n",
       "           2.0986509e+00, 2.4314561e+00, 1.8257759e+00],\n",
       "          [1.7129129e-01, 0.0000000e+00, 6.5368581e+00, ...,\n",
       "           1.3893254e+00, 2.7241943e+00, 1.6401808e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 4.4607372e+00, ...,\n",
       "           9.8481858e-01, 2.4318736e+00, 3.2456553e-01]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 1.8014989e+00, ...,\n",
       "           5.8096361e-01, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 7.8289032e-02, 2.6667051e+00, ...,\n",
       "           1.2814753e+00, 2.5595374e+00, 0.0000000e+00],\n",
       "          [2.8260770e+00, 1.4810719e+00, 1.8509406e+00, ...,\n",
       "           1.5765892e+00, 2.8379196e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [1.2301748e+00, 4.1712999e-02, 3.6946344e+00, ...,\n",
       "           1.2115459e+00, 1.9613425e+00, 0.0000000e+00],\n",
       "          [7.1867168e-02, 0.0000000e+00, 4.0800152e+00, ...,\n",
       "           5.5496353e-01, 2.8935275e+00, 0.0000000e+00],\n",
       "          [1.1174088e+00, 3.9302790e-01, 2.8069491e+00, ...,\n",
       "           6.1878890e-01, 4.2867150e+00, 0.0000000e+00]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18451, shape=(1, 122, 122, 64), dtype=float32, numpy=\n",
       " array([[[[5.9681354e+00, 1.2375951e+00, 3.5743589e+00, ...,\n",
       "           1.8788213e+00, 2.8501279e+00, 1.8846335e+00],\n",
       "          [5.3306884e-01, 0.0000000e+00, 3.0363927e+00, ...,\n",
       "           1.2632602e+00, 4.6234756e+00, 1.2528231e+00],\n",
       "          [1.9981778e+00, 8.5741246e-01, 2.9181707e+00, ...,\n",
       "           3.0645342e+00, 4.0866342e+00, 1.7085152e+00],\n",
       "          ...,\n",
       "          [1.3779817e+00, 8.3172131e-01, 4.6670547e+00, ...,\n",
       "           1.9347452e+00, 4.2430034e+00, 1.6586914e+00],\n",
       "          [3.7510979e-01, 5.8266407e-01, 4.0758114e+00, ...,\n",
       "           2.0879819e+00, 4.2152991e+00, 1.6029925e+00],\n",
       "          [8.8994199e-01, 4.1164625e-01, 2.6028910e+00, ...,\n",
       "           1.6459450e+00, 6.9295034e+00, 1.9084365e+00]],\n",
       " \n",
       "         [[6.3562036e-02, 1.1834404e-01, 3.1098962e+00, ...,\n",
       "           1.6143316e+00, 2.4183404e+00, 7.0912462e-01],\n",
       "          [4.0315161e+00, 2.4711881e+00, 3.2267590e+00, ...,\n",
       "           1.5122331e+00, 5.5067635e-01, 8.1789809e-01],\n",
       "          [1.5398114e+00, 1.8579283e+00, 3.0331378e+00, ...,\n",
       "           2.1561124e+00, 3.2563157e+00, 6.7987090e-01],\n",
       "          ...,\n",
       "          [4.0103998e+00, 1.7277775e+00, 6.8060322e+00, ...,\n",
       "           3.0499737e+00, 2.9821937e+00, 1.1369240e+00],\n",
       "          [3.9189887e+00, 1.8599243e+00, 6.0290918e+00, ...,\n",
       "           3.1305921e+00, 7.9568726e-01, 9.8722702e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 3.3478978e+00, ...,\n",
       "           1.5928129e+00, 3.9677269e+00, 7.7439159e-01]],\n",
       " \n",
       "         [[1.5120604e+00, 7.5332248e-01, 2.7338288e+00, ...,\n",
       "           2.0218074e+00, 5.2214580e+00, 1.1937690e+00],\n",
       "          [3.4087443e+00, 2.3960230e+00, 3.0577002e+00, ...,\n",
       "           2.1335685e+00, 2.3650990e-01, 1.3611975e+00],\n",
       "          [1.9614863e+00, 1.8639481e+00, 2.8747313e+00, ...,\n",
       "           1.8246619e+00, 3.1080749e+00, 9.1557080e-01],\n",
       "          ...,\n",
       "          [8.4063238e-01, 8.1690454e-01, 7.4535666e+00, ...,\n",
       "           2.1885338e+00, 3.9922655e+00, 1.3859680e+00],\n",
       "          [8.5709543e+00, 3.9455926e+00, 6.4603109e+00, ...,\n",
       "           3.0268004e+00, 3.2944944e+00, 1.3415022e+00],\n",
       "          [3.5895174e+00, 1.5337481e+00, 3.5591483e+00, ...,\n",
       "           2.1458240e+00, 3.3600242e+00, 1.2531636e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.6068728e+00, 9.3249512e-01, 3.6107721e+00, ...,\n",
       "           2.1056957e+00, 2.7280929e+00, 1.0969012e+00],\n",
       "          [3.1103921e+00, 2.1510906e+00, 5.9559736e+00, ...,\n",
       "           2.0269592e+00, 6.9594365e-01, 1.0604999e+00],\n",
       "          [2.0792942e+00, 1.0220642e+00, 6.3248181e+00, ...,\n",
       "           1.1861449e+00, 3.1857586e+00, 1.0948975e+00],\n",
       "          ...,\n",
       "          [2.5256267e+00, 1.3135843e+00, 4.5435328e+00, ...,\n",
       "           3.2643559e+00, 3.1595178e+00, 1.1722708e+00],\n",
       "          [4.9982324e+00, 2.9048550e+00, 5.2200432e+00, ...,\n",
       "           3.3082452e+00, 1.0563376e+00, 1.6314445e+00],\n",
       "          [6.2088275e+00, 3.4067402e+00, 4.8838143e+00, ...,\n",
       "           2.5223279e+00, 2.3780119e+00, 1.6177862e+00]],\n",
       " \n",
       "         [[2.0720599e+00, 8.0953956e-01, 4.8225460e+00, ...,\n",
       "           2.6042888e+00, 4.4095421e+00, 7.6320833e-01],\n",
       "          [2.6535921e+00, 1.6100299e+00, 6.0702720e+00, ...,\n",
       "           2.3996382e+00, 4.0999060e+00, 6.8453437e-01],\n",
       "          [1.2386982e+00, 1.9843352e+00, 6.2374792e+00, ...,\n",
       "           1.6913016e+00, 3.1834147e+00, 5.7920164e-01],\n",
       "          ...,\n",
       "          [2.3054819e+00, 7.0409673e-01, 4.2740092e+00, ...,\n",
       "           3.2711680e+00, 3.8300798e+00, 6.5573889e-01],\n",
       "          [6.5504313e-03, 4.8746151e-01, 5.8882117e+00, ...,\n",
       "           2.9545116e+00, 3.3838012e+00, 7.3979193e-01],\n",
       "          [2.7690399e+00, 5.1345867e-01, 6.3489299e+00, ...,\n",
       "           1.8833271e+00, 3.2450805e+00, 8.7781030e-01]],\n",
       " \n",
       "         [[0.0000000e+00, 7.8289032e-02, 4.5836415e+00, ...,\n",
       "           2.0397882e+00, 4.0656357e+00, 1.2229824e+00],\n",
       "          [2.8260770e+00, 1.4810719e+00, 3.4298906e+00, ...,\n",
       "           1.8649101e+00, 2.7512894e+00, 1.5818586e+00],\n",
       "          [1.3138847e+00, 3.4863031e-01, 3.9609568e+00, ...,\n",
       "           1.3209891e+00, 3.6351752e+00, 1.8662691e+00],\n",
       "          ...,\n",
       "          [1.8614745e+00, 1.4219646e+00, 3.6012931e+00, ...,\n",
       "           2.1210132e+00, 2.1905584e+00, 1.4253111e+00],\n",
       "          [1.2301748e+00, 3.3958256e-01, 5.8775458e+00, ...,\n",
       "           2.0986509e+00, 5.2476988e+00, 1.8257759e+00],\n",
       "          [1.1174088e+00, 3.9302790e-01, 6.5368581e+00, ...,\n",
       "           1.3893254e+00, 4.2867150e+00, 1.6401808e+00]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18456, shape=(1, 122, 122, 128), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  0.        ,  0.        , ...,  7.4137955 ,\n",
       "            0.        , 13.3743515 ],\n",
       "          [ 0.        ,  0.        ,  3.2290163 , ...,  7.637387  ,\n",
       "            0.        ,  0.19126007],\n",
       "          [ 0.        ,  0.        ,  1.9843664 , ...,  2.6460204 ,\n",
       "            0.        ,  1.332549  ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  4.501585  , ...,  8.748632  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  2.5053594 , ...,  7.39536   ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  5.6661777 , ..., 10.509218  ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  2.9316423 ,  0.        , ...,  6.0472293 ,\n",
       "            0.        , 16.325405  ],\n",
       "          [ 0.        ,  2.9325955 ,  0.5993299 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  2.543326  ,  0.        , ...,  5.011037  ,\n",
       "            2.6481314 ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  3.74162   ,  1.0352231 , ...,  5.9741635 ,\n",
       "            0.        ,  0.27838188],\n",
       "          [ 0.        ,  4.0829725 ,  0.74529374, ...,  8.646559  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  3.1626785 ,  6.5439587 , ..., 15.333022  ,\n",
       "            6.345645  ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.30420935,  0.        , ...,  6.4394712 ,\n",
       "            0.        , 17.17466   ],\n",
       "          [ 0.        ,  0.        ,  0.03421464, ...,  0.        ,\n",
       "            0.        ,  0.11571887],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  4.5571394 ,\n",
       "            1.8846555 ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  1.1662343 , ...,  6.246342  ,\n",
       "            0.596324  ,  3.648372  ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 10.674583  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.1758382 ,  5.3224487 , ..., 13.539256  ,\n",
       "            5.0052967 ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.        ,  0.13897496,  0.        , ...,  9.121294  ,\n",
       "            0.        , 14.699673  ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.37102306,\n",
       "            0.        ,  1.5778364 ],\n",
       "          [ 0.        ,  0.33893868,  0.        , ...,  5.2832246 ,\n",
       "            1.4848108 ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.28707355,  0.        , ...,  4.5869603 ,\n",
       "            0.        ,  4.2335033 ],\n",
       "          [ 0.        ,  0.        ,  1.0819427 , ...,  3.8371599 ,\n",
       "            0.        ,  2.6221254 ],\n",
       "          [ 0.        ,  0.        ,  6.4435267 , ...,  8.672868  ,\n",
       "            0.74058694,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  3.225328  ,  0.        , ...,  9.403758  ,\n",
       "            0.        , 15.179878  ],\n",
       "          [ 0.        ,  1.4859768 ,  0.42268968, ...,  1.6621    ,\n",
       "            0.        ,  0.17377234],\n",
       "          [ 0.        ,  0.27386224,  0.21511516, ...,  3.789991  ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  3.4149961 ,  0.        , ...,  3.4582944 ,\n",
       "            0.        ,  3.5004249 ],\n",
       "          [ 0.        ,  3.9008338 ,  0.7055136 , ...,  6.458718  ,\n",
       "            0.        ,  1.6608466 ],\n",
       "          [ 0.        ,  2.4721277 ,  6.6893044 , ...,  9.488347  ,\n",
       "            4.0898423 ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  5.160045  ,  0.        , ..., 10.247623  ,\n",
       "            0.5194198 , 11.575818  ],\n",
       "          [ 0.        ,  5.603079  ,  1.3594064 , ...,  2.3479264 ,\n",
       "            1.0568248 ,  0.22624967],\n",
       "          [ 0.        ,  4.8267493 ,  1.0533588 , ...,  6.034687  ,\n",
       "            0.8244575 ,  0.20249228],\n",
       "          ...,\n",
       "          [ 0.        ,  4.180613  ,  0.        , ...,  3.301988  ,\n",
       "            1.4452773 ,  2.2813704 ],\n",
       "          [ 0.        ,  5.4842587 ,  0.5499211 , ...,  7.965998  ,\n",
       "            0.29052496,  1.7001    ],\n",
       "          [ 0.        ,  3.659507  ,  6.12951   , ...,  9.774948  ,\n",
       "            1.9411083 ,  0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18461, shape=(1, 122, 122, 128), dtype=float32, numpy=\n",
       " array([[[[ 0.90335965,  5.2911115 ,  3.3635702 , ...,  0.59007514,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.13691995,  0.        ,  0.        , ...,  7.278819  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  5.6187296 ,  0.24879508, ...,  6.4565473 ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [10.692507  ,  1.2769079 ,  0.        , ..., 11.103238  ,\n",
       "            0.        ,  0.        ],\n",
       "          [12.759658  ,  3.0718963 ,  0.        , ..., 10.014089  ,\n",
       "            0.        ,  0.        ],\n",
       "          [10.076842  ,  0.        ,  2.2892594 , ...,  8.0370035 ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  1.8716278 ,  0.6702349 , ...,  3.891216  ,\n",
       "           13.467812  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 16.157785  ,\n",
       "            7.369209  ,  0.        ],\n",
       "          [ 0.        ,  3.1352642 ,  2.753837  , ..., 14.358225  ,\n",
       "            2.519834  ,  0.        ],\n",
       "          ...,\n",
       "          [12.645919  ,  0.        ,  0.        , ..., 19.411982  ,\n",
       "            0.        ,  0.        ],\n",
       "          [14.565379  ,  0.        ,  0.        , ..., 20.370995  ,\n",
       "            0.        ,  0.        ],\n",
       "          [12.517814  ,  0.        ,  4.020161  , ..., 13.520407  ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 1.0025578 ,  1.8051809 ,  0.        , ...,  5.1573267 ,\n",
       "           13.651896  ,  0.        ],\n",
       "          [ 0.89763707,  0.        ,  0.        , ..., 20.199663  ,\n",
       "            9.717629  ,  0.        ],\n",
       "          [ 0.        ,  4.5576253 ,  0.26440996, ..., 17.468662  ,\n",
       "            1.6595337 ,  0.        ],\n",
       "          ...,\n",
       "          [11.111337  ,  0.        ,  0.        , ..., 11.437863  ,\n",
       "            4.806573  ,  0.        ],\n",
       "          [13.496766  ,  0.        ,  4.918748  , ..., 14.340888  ,\n",
       "            0.        ,  0.        ],\n",
       "          [12.1926985 ,  0.        ,  5.7062654 , ..., 11.909839  ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.0960846 ,  4.977436  ,  0.8306504 , ...,  1.6291299 ,\n",
       "           19.17388   ,  0.        ],\n",
       "          [ 1.2419225 ,  0.        ,  0.        , ..., 12.158277  ,\n",
       "           14.215001  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 15.274058  ,\n",
       "           11.799453  ,  0.        ],\n",
       "          ...,\n",
       "          [ 8.139327  ,  0.        ,  2.5977476 , ..., 14.615777  ,\n",
       "            9.406342  ,  0.        ],\n",
       "          [13.278979  ,  0.        ,  0.        , ..., 18.93794   ,\n",
       "            0.        ,  0.        ],\n",
       "          [12.848459  ,  0.        ,  0.        , ..., 17.25257   ,\n",
       "            0.        ,  0.25807828]],\n",
       " \n",
       "         [[ 2.5701892 ,  5.647223  ,  1.4164362 , ...,  0.03415668,\n",
       "           18.112734  ,  0.        ],\n",
       "          [ 5.716974  ,  0.        ,  0.        , ...,  8.609418  ,\n",
       "           15.047535  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 11.551025  ,\n",
       "           10.876178  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.8544028 ,  0.        ,  0.        , ...,  9.0887785 ,\n",
       "           12.136883  ,  0.        ],\n",
       "          [ 7.384761  ,  0.        ,  0.        , ..., 13.355641  ,\n",
       "            2.5766382 ,  0.        ],\n",
       "          [ 9.833911  ,  0.        ,  0.83120954, ..., 12.663215  ,\n",
       "            0.        ,  2.1821396 ]],\n",
       " \n",
       "         [[ 0.        ,  1.5714356 ,  1.5175676 , ...,  0.        ,\n",
       "           19.650484  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  2.3714833 ,\n",
       "           14.222293  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  3.2026145 ,\n",
       "            9.533409  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  1.6131979 ,\n",
       "           13.812535  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  3.0628982 ,\n",
       "            5.6563478 ,  0.        ],\n",
       "          [ 0.41650224,  0.        ,  0.        , ...,  4.1328416 ,\n",
       "            0.        ,  0.5613545 ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18462, shape=(1, 61, 61, 128), dtype=float32, numpy=\n",
       " array([[[[ 0.90335965,  5.2911115 ,  3.3635702 , ..., 16.157785  ,\n",
       "           13.467812  ,  0.        ],\n",
       "          [ 6.49244   ,  7.6697583 ,  2.753837  , ..., 14.358225  ,\n",
       "            3.801707  ,  0.        ],\n",
       "          [10.109211  ,  0.        ,  0.        , ..., 12.588676  ,\n",
       "            5.330665  ,  0.        ],\n",
       "          ...,\n",
       "          [ 7.7694435 ,  1.4039085 ,  5.442639  , ..., 14.210754  ,\n",
       "            3.6872745 ,  0.        ],\n",
       "          [12.645919  ,  1.6126808 ,  0.        , ..., 19.411982  ,\n",
       "            0.        ,  0.        ],\n",
       "          [14.565379  ,  3.0718963 ,  4.020161  , ..., 20.370995  ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 8.241002  ,  2.5489717 ,  0.        , ..., 20.199663  ,\n",
       "           17.124575  ,  0.        ],\n",
       "          [ 2.2410674 ,  4.714155  ,  0.26440996, ..., 17.468662  ,\n",
       "            3.811244  ,  1.4432968 ],\n",
       "          [ 0.        ,  0.        ,  4.313617  , ..., 15.9175    ,\n",
       "           13.801598  ,  0.        ],\n",
       "          ...,\n",
       "          [ 3.9032738 ,  0.        ,  0.        , ..., 16.537523  ,\n",
       "            7.92339   ,  0.        ],\n",
       "          [11.111337  ,  0.        ,  0.2987219 , ..., 14.437698  ,\n",
       "            6.9413257 ,  0.        ],\n",
       "          [13.496766  ,  0.        ,  6.8480735 , ..., 16.721523  ,\n",
       "            0.57783437,  0.        ]],\n",
       " \n",
       "         [[ 8.46665   ,  9.665137  ,  2.6125484 , ..., 20.045984  ,\n",
       "           17.86168   ,  0.        ],\n",
       "          [ 6.7742143 ,  0.        ,  0.        , ..., 20.397203  ,\n",
       "            5.466957  ,  0.        ],\n",
       "          [ 2.1807997 ,  2.3755202 ,  3.7958934 , ..., 10.262048  ,\n",
       "           13.588227  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  2.3629458 , ..., 16.498835  ,\n",
       "            7.3738904 ,  0.        ],\n",
       "          [ 0.        ,  0.5992679 ,  0.        , ..., 14.576467  ,\n",
       "            4.6635003 ,  0.        ],\n",
       "          [ 8.824046  ,  0.        ,  5.9958034 , ..., 14.275919  ,\n",
       "            0.        ,  5.0799923 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.        ,  1.909965  ,  4.536213  , ..., 13.960061  ,\n",
       "           17.739258  ,  0.        ],\n",
       "          [ 5.035656  ,  0.        ,  4.743035  , ..., 17.03263   ,\n",
       "           11.067599  ,  0.        ],\n",
       "          [11.482644  ,  3.2595146 ,  0.        , ..., 18.459435  ,\n",
       "            9.216839  ,  0.        ],\n",
       "          ...,\n",
       "          [ 4.024631  ,  0.        ,  1.8628355 , ..., 19.193474  ,\n",
       "           11.589921  ,  0.        ],\n",
       "          [ 5.4782643 ,  0.        ,  2.3736014 , ..., 18.072369  ,\n",
       "           11.41199   ,  0.        ],\n",
       "          [ 9.9888525 ,  0.        ,  1.7480907 , ..., 20.00036   ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 1.2419225 ,  4.977436  ,  3.976933  , ..., 13.69586   ,\n",
       "           21.716808  ,  0.        ],\n",
       "          [ 0.        ,  0.21800804,  2.0655117 , ..., 21.799639  ,\n",
       "           11.986774  ,  0.        ],\n",
       "          [ 6.4206386 ,  2.630251  ,  0.        , ..., 18.960762  ,\n",
       "           11.404205  ,  0.        ],\n",
       "          ...,\n",
       "          [ 2.487029  ,  2.2350588 ,  0.        , ..., 16.254627  ,\n",
       "            9.650759  ,  0.        ],\n",
       "          [10.642999  ,  0.        ,  8.680418  , ..., 14.615777  ,\n",
       "           11.250156  ,  0.        ],\n",
       "          [13.278979  ,  0.        ,  0.        , ..., 18.93794   ,\n",
       "            0.        ,  0.25807828]],\n",
       " \n",
       "         [[ 5.716974  ,  5.647223  ,  1.5175676 , ...,  8.609418  ,\n",
       "           19.650484  ,  0.        ],\n",
       "          [ 0.        ,  0.6487142 ,  0.        , ..., 12.588856  ,\n",
       "           11.239388  ,  0.        ],\n",
       "          [ 0.        ,  2.4334173 ,  4.0343404 , ..., 15.264626  ,\n",
       "           12.183584  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  1.1915292 ,  0.5727015 , ..., 15.488183  ,\n",
       "           13.220968  ,  0.        ],\n",
       "          [ 0.8544028 ,  0.        ,  1.9960397 , ..., 11.881859  ,\n",
       "           16.300926  ,  0.        ],\n",
       "          [ 9.833911  ,  0.        ,  0.83120954, ..., 13.355641  ,\n",
       "            5.6563478 ,  2.1821396 ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18467, shape=(1, 61, 61, 256), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  0.12350941,  1.5124602 , ...,  0.05191392,\n",
       "            4.3585587 , 15.089161  ],\n",
       "          [ 0.        ,  0.        ,  1.129696  , ...,  0.        ,\n",
       "            5.503551  , 16.341154  ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            2.9893737 , 19.031488  ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.8178045 , ...,  0.        ,\n",
       "            1.0019099 , 15.37249   ],\n",
       "          [ 0.        ,  0.88163835,  0.751823  , ...,  0.        ,\n",
       "            0.        , 14.932926  ],\n",
       "          [ 0.        ,  0.6216947 ,  0.8040445 , ...,  0.        ,\n",
       "            0.        , 17.495886  ]],\n",
       " \n",
       "         [[ 0.20063064,  1.3165586 ,  6.4495597 , ...,  0.        ,\n",
       "            3.9717245 ,  9.55275   ],\n",
       "          [ 2.2024572 ,  0.        ,  8.842888  , ...,  0.        ,\n",
       "            4.019517  ,  3.1977115 ],\n",
       "          [ 1.6749558 ,  0.        ,  5.9243875 , ...,  0.        ,\n",
       "            3.5835123 ,  6.498163  ],\n",
       "          ...,\n",
       "          [ 2.443767  ,  2.43899   ,  2.487833  , ...,  0.        ,\n",
       "           14.83382   , 11.22067   ],\n",
       "          [ 7.3985906 ,  0.        ,  5.619669  , ...,  0.        ,\n",
       "           14.909955  ,  9.37314   ],\n",
       "          [ 0.        ,  0.        ,  4.285945  , ...,  0.        ,\n",
       "            2.405263  , 15.62617   ]],\n",
       " \n",
       "         [[ 0.        ,  6.3373017 ,  3.8133407 , ...,  0.        ,\n",
       "            5.563932  ,  7.7698975 ],\n",
       "          [ 1.6629752 ,  0.        ,  2.095275  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 2.030357  ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  3.1894078 ],\n",
       "          ...,\n",
       "          [ 0.8066479 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            6.838333  , 10.612687  ],\n",
       "          [ 6.7210665 ,  0.        ,  0.9164647 , ...,  0.        ,\n",
       "            6.573654  ,  6.057619  ],\n",
       "          [ 0.        ,  0.        ,  1.4668831 , ...,  0.        ,\n",
       "            0.08227548, 14.470276  ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.20611754,  0.        ,  2.4105046 , ...,  1.5407048 ,\n",
       "            6.097405  , 10.918232  ],\n",
       "          [ 2.3221264 ,  0.        ,  0.        , ...,  1.436436  ,\n",
       "            5.084846  ,  6.2095957 ],\n",
       "          [ 5.8634243 ,  1.4817779 ,  0.        , ...,  1.4508312 ,\n",
       "            7.3899636 ,  7.6788874 ],\n",
       "          ...,\n",
       "          [ 6.7201176 ,  0.        ,  0.        , ...,  2.6968899 ,\n",
       "            4.246231  ,  9.017837  ],\n",
       "          [ 8.027888  ,  0.        ,  0.        , ...,  1.0171552 ,\n",
       "            0.        ,  7.087899  ],\n",
       "          [ 0.        ,  0.        ,  0.32234675, ...,  1.0868492 ,\n",
       "            0.        , 14.281426  ]],\n",
       " \n",
       "         [[ 0.9162258 ,  0.98030967,  3.0613098 , ...,  2.8508976 ,\n",
       "           10.440271  ,  7.1247706 ],\n",
       "          [ 4.2023883 ,  0.        ,  1.1258748 , ...,  3.6799297 ,\n",
       "           12.302796  ,  3.4920986 ],\n",
       "          [ 7.4226327 ,  0.        ,  0.        , ...,  0.28610876,\n",
       "           10.258319  ,  5.4956675 ],\n",
       "          ...,\n",
       "          [ 5.8306756 ,  3.1784391 ,  0.        , ...,  1.7246696 ,\n",
       "            3.6148732 ,  5.884995  ],\n",
       "          [ 7.2962494 ,  0.        ,  1.9273416 , ...,  0.        ,\n",
       "            1.819384  ,  3.926362  ],\n",
       "          [ 0.        ,  0.        ,  3.2977283 , ...,  1.0104825 ,\n",
       "            0.09972118, 13.111877  ]],\n",
       " \n",
       "         [[ 0.        ,  5.226384  ,  0.        , ...,  0.09590656,\n",
       "           13.225093  ,  4.1745405 ],\n",
       "          [ 1.8985986 ,  2.5246592 ,  0.        , ...,  2.119189  ,\n",
       "           15.272671  ,  1.1031537 ],\n",
       "          [ 1.5897202 ,  0.        ,  0.        , ...,  0.        ,\n",
       "           16.20723   ,  1.4234744 ],\n",
       "          ...,\n",
       "          [ 1.1856394 ,  2.8997788 ,  0.        , ...,  0.        ,\n",
       "           12.323822  ,  6.803133  ],\n",
       "          [ 2.5956478 ,  2.653714  ,  0.        , ...,  0.        ,\n",
       "           17.069687  ,  3.0535517 ],\n",
       "          [ 0.        ,  0.87649524,  0.        , ...,  1.4863195 ,\n",
       "           11.938015  ,  8.746216  ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18472, shape=(1, 61, 61, 256), dtype=float32, numpy=\n",
       " array([[[[6.7136798e+00, 0.0000000e+00, 4.2929268e+00, ...,\n",
       "           0.0000000e+00, 8.6683464e+00, 4.1586266e+00],\n",
       "          [5.4477854e+00, 0.0000000e+00, 2.0923214e+00, ...,\n",
       "           0.0000000e+00, 8.2133083e+00, 4.3431940e+00],\n",
       "          [8.4579477e+00, 0.0000000e+00, 5.5235314e+00, ...,\n",
       "           0.0000000e+00, 7.1559677e+00, 6.3638413e-01],\n",
       "          ...,\n",
       "          [4.7277932e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.6489658e+00, 6.4316683e+00],\n",
       "          [5.1586504e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.9817266e+00, 5.6847777e+00],\n",
       "          [6.8292890e+00, 0.0000000e+00, 4.7343097e+00, ...,\n",
       "           0.0000000e+00, 1.0769296e+00, 2.7197688e+00]],\n",
       " \n",
       "         [[3.1092248e+00, 3.6117368e+00, 4.0765758e+00, ...,\n",
       "           0.0000000e+00, 1.3891849e+01, 5.8763328e+00],\n",
       "          [0.0000000e+00, 5.0315409e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.1049073e+01, 4.5268607e+00],\n",
       "          [0.0000000e+00, 1.3849107e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.2746186e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [9.5187962e-01, 6.7557473e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.7958679e+00, 4.2555594e+00],\n",
       "          [1.0630735e+01, 3.9882836e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.6227884e+00, 0.0000000e+00],\n",
       "          [1.5824013e+01, 6.2290459e+00, 8.8111854e-01, ...,\n",
       "           0.0000000e+00, 3.8484237e-01, 0.0000000e+00]],\n",
       " \n",
       "         [[1.0717193e+01, 3.0156844e+00, 5.5674429e+00, ...,\n",
       "           1.1484448e+00, 1.2428666e+01, 4.0208983e+00],\n",
       "          [0.0000000e+00, 3.0473979e+00, 4.7591797e-01, ...,\n",
       "           3.8247211e+00, 9.0061445e+00, 3.2081467e-01],\n",
       "          [0.0000000e+00, 1.1067851e-01, 1.5139097e+00, ...,\n",
       "           2.7790482e+00, 3.4328084e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 2.9409671e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.6268091e+00, 0.0000000e+00],\n",
       "          [4.0262809e+00, 3.0416691e+00, 9.5004618e-01, ...,\n",
       "           0.0000000e+00, 6.0269256e+00, 0.0000000e+00],\n",
       "          [1.2669180e+01, 7.3437004e+00, 2.3472188e+00, ...,\n",
       "           0.0000000e+00, 1.8738934e+00, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[6.3304853e+00, 8.6634159e+00, 4.4098516e+00, ...,\n",
       "           3.6437278e+00, 8.0352039e+00, 3.9362023e-03],\n",
       "          [0.0000000e+00, 1.0743227e+01, 5.4887384e-01, ...,\n",
       "           4.2301645e+00, 5.1167393e+00, 2.0562944e+00],\n",
       "          [4.7289362e+00, 6.3467159e+00, 5.6058717e-01, ...,\n",
       "           0.0000000e+00, 1.2305596e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 7.7952856e-01, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.2248635e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 4.0921059e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.8104362e+00, 0.0000000e+00],\n",
       "          [9.0598613e-01, 1.0681641e+01, 5.8152170e+00, ...,\n",
       "           0.0000000e+00, 2.5455599e+00, 0.0000000e+00]],\n",
       " \n",
       "         [[7.0154748e+00, 1.0391834e+01, 5.7555866e+00, ...,\n",
       "           4.6253939e+00, 1.0055408e+01, 1.6778945e+00],\n",
       "          [0.0000000e+00, 1.5468839e+01, 0.0000000e+00, ...,\n",
       "           3.5514169e+00, 9.1289234e+00, 6.4558339e+00],\n",
       "          [2.4715233e+00, 1.4512867e+01, 0.0000000e+00, ...,\n",
       "           1.4389348e+00, 3.8770740e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 1.0680674e+01, 2.5314229e+00, ...,\n",
       "           8.3194184e-01, 4.0315385e+00, 0.0000000e+00],\n",
       "          [1.4427415e-01, 1.1826988e+01, 2.8985622e+00, ...,\n",
       "           1.4622164e+00, 1.0155921e+01, 0.0000000e+00],\n",
       "          [5.3312364e+00, 1.2870301e+01, 2.7674196e+00, ...,\n",
       "           0.0000000e+00, 3.2686830e+00, 8.1757510e-01]],\n",
       " \n",
       "         [[8.9389772e+00, 1.2776399e+01, 4.1254396e+00, ...,\n",
       "           5.6611280e+00, 9.4732542e+00, 2.2340372e+00],\n",
       "          [1.5469968e+00, 1.6072765e+01, 4.1916289e+00, ...,\n",
       "           3.5406628e+00, 1.1934734e+01, 5.9544573e+00],\n",
       "          [5.8517818e+00, 1.3442806e+01, 7.1610183e-01, ...,\n",
       "           4.6174960e+00, 9.2412930e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [1.1091788e+01, 1.6405138e+01, 1.8112100e+00, ...,\n",
       "           5.4894185e+00, 5.6997147e+00, 0.0000000e+00],\n",
       "          [1.8872332e+01, 1.9897655e+01, 5.1606865e+00, ...,\n",
       "           6.7441802e+00, 7.6694756e+00, 0.0000000e+00],\n",
       "          [1.4492323e+01, 1.4422197e+01, 5.7044592e+00, ...,\n",
       "           1.3354097e-01, 3.6620553e+00, 2.7800078e+00]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18477, shape=(1, 61, 61, 256), dtype=float32, numpy=\n",
       " array([[[[ 9.845143  ,  4.1386414 ,  5.250026  , ...,  9.483258  ,\n",
       "            9.415809  ,  5.875525  ],\n",
       "          [10.695194  , 12.010979  ,  9.340929  , ..., 12.466571  ,\n",
       "            9.143992  ,  5.161332  ],\n",
       "          [16.028597  , 13.42219   ,  9.40622   , ..., 13.310785  ,\n",
       "            5.373281  ,  2.3013496 ],\n",
       "          ...,\n",
       "          [ 4.254375  ,  8.133602  , 16.315565  , ..., 11.320421  ,\n",
       "            0.07001461,  2.6544218 ],\n",
       "          [ 4.7109256 , 10.053141  , 17.585129  , ..., 12.670335  ,\n",
       "            0.        ,  4.7310667 ],\n",
       "          [ 6.118442  ,  8.43514   , 10.02401   , ..., 11.172848  ,\n",
       "            0.        ,  1.1908066 ]],\n",
       " \n",
       "         [[14.882371  ,  6.7899103 , 10.293592  , ...,  5.1012583 ,\n",
       "           13.408823  ,  7.18441   ],\n",
       "          [ 2.268928  , 20.467567  , 14.452572  , ...,  6.246692  ,\n",
       "           12.525313  ,  8.338333  ],\n",
       "          [ 6.6657205 , 19.463156  , 11.675172  , ...,  7.7215757 ,\n",
       "            8.380305  ,  2.6063704 ],\n",
       "          ...,\n",
       "          [ 7.5961165 , 15.392947  , 12.210699  , ...,  3.69537   ,\n",
       "            2.3988123 ,  1.0973867 ],\n",
       "          [ 2.687904  , 19.387823  , 16.998415  , ...,  3.5904427 ,\n",
       "            3.4923947 ,  4.2219615 ],\n",
       "          [ 3.0688095 , 15.824711  , 11.554549  , ...,  6.2152147 ,\n",
       "            2.892279  ,  0.        ]],\n",
       " \n",
       "         [[16.917719  , 12.756436  , 10.925372  , ...,  5.0895853 ,\n",
       "           14.301987  ,  2.9082482 ],\n",
       "          [ 2.8771496 , 22.185616  , 11.9358225 , ...,  5.701084  ,\n",
       "           10.811709  ,  3.963231  ],\n",
       "          [ 1.759455  , 14.766032  ,  5.9783764 , ...,  7.637831  ,\n",
       "            7.6626654 ,  0.        ],\n",
       "          ...,\n",
       "          [ 2.7678788 ,  8.319596  ,  5.0929313 , ...,  3.6829689 ,\n",
       "            0.67223024,  0.        ],\n",
       "          [ 0.5988064 , 15.095595  , 14.157379  , ...,  1.651116  ,\n",
       "            1.0741582 ,  0.        ],\n",
       "          [ 2.6412628 , 13.411914  , 11.002771  , ...,  5.2710266 ,\n",
       "            4.2024403 ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 6.6830487 , 10.703494  ,  4.3096623 , ..., 11.146498  ,\n",
       "           11.562349  ,  2.6080353 ],\n",
       "          [ 0.        , 12.330942  ,  4.3481736 , ..., 13.607896  ,\n",
       "           10.002522  ,  0.38742346],\n",
       "          [ 0.7309332 , 13.760343  ,  4.1846256 , ..., 11.818776  ,\n",
       "            6.4683456 ,  0.        ],\n",
       "          ...,\n",
       "          [ 4.6065063 , 10.930765  ,  0.        , ...,  8.905117  ,\n",
       "            3.362361  ,  0.        ],\n",
       "          [ 0.37904248, 14.590373  ,  1.6076195 , ...,  7.4135404 ,\n",
       "            5.5290437 ,  0.        ],\n",
       "          [ 2.4043634 , 12.793711  ,  2.6219919 , ..., 11.471007  ,\n",
       "            4.3234015 ,  0.        ]],\n",
       " \n",
       "         [[11.99077   , 15.665952  ,  9.431014  , ..., 14.050547  ,\n",
       "           13.330548  ,  0.        ],\n",
       "          [ 3.6547809 , 19.25125   , 11.390724  , ..., 19.23314   ,\n",
       "           14.044085  ,  0.        ],\n",
       "          [ 0.84951264, 21.763277  , 12.10079   , ..., 17.80992   ,\n",
       "           10.380922  ,  0.        ],\n",
       "          ...,\n",
       "          [ 6.2663636 , 18.065369  ,  5.932158  , ..., 13.656009  ,\n",
       "            9.015357  ,  0.        ],\n",
       "          [ 0.7232686 , 21.731602  ,  7.773307  , ..., 10.188707  ,\n",
       "           10.4363    ,  0.        ],\n",
       "          [ 0.        , 17.713633  ,  6.3342505 , ..., 11.6123495 ,\n",
       "            7.9317813 ,  0.        ]],\n",
       " \n",
       "         [[17.944008  , 12.479876  ,  9.271409  , ..., 11.905372  ,\n",
       "           10.859466  ,  0.        ],\n",
       "          [14.5244875 , 18.174173  , 12.644319  , ..., 16.877005  ,\n",
       "           12.487091  ,  0.        ],\n",
       "          [ 4.7339807 , 20.432196  , 13.983534  , ..., 16.067993  ,\n",
       "           10.443494  ,  0.        ],\n",
       "          ...,\n",
       "          [10.651814  , 16.413631  , 15.18428   , ..., 12.699421  ,\n",
       "           10.910305  ,  0.        ],\n",
       "          [13.529551  , 18.55251   , 14.618913  , ...,  9.425269  ,\n",
       "            9.572464  ,  0.        ],\n",
       "          [ 6.425168  , 14.366243  ,  9.59562   , ...,  9.493777  ,\n",
       "            7.2129483 ,  0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18482, shape=(1, 61, 61, 256), dtype=float32, numpy=\n",
       " array([[[[1.56661844e+01, 1.74855595e+01, 2.65853143e+00, ...,\n",
       "           1.45268097e+01, 4.13081789e+00, 2.29943848e+00],\n",
       "          [2.77007103e+01, 5.62196312e+01, 9.52968299e-01, ...,\n",
       "           6.13861084e+00, 2.71756554e+00, 0.00000000e+00],\n",
       "          [1.88725758e+01, 5.97101173e+01, 1.56027484e+00, ...,\n",
       "           6.12836552e+00, 0.00000000e+00, 1.84847450e+00],\n",
       "          ...,\n",
       "          [4.06041107e+01, 5.34962234e+01, 4.10943776e-01, ...,\n",
       "           3.65248919e-01, 0.00000000e+00, 1.15705729e+01],\n",
       "          [4.79169998e+01, 6.57790985e+01, 0.00000000e+00, ...,\n",
       "           5.40925455e+00, 0.00000000e+00, 1.18881302e+01],\n",
       "          [3.40203896e+01, 7.87267990e+01, 0.00000000e+00, ...,\n",
       "           7.51163864e+00, 0.00000000e+00, 3.92692637e+00]],\n",
       " \n",
       "         [[2.06943302e+01, 7.05154133e+00, 1.42122564e+01, ...,\n",
       "           3.27518578e+01, 5.06324816e+00, 5.82424450e+00],\n",
       "          [3.38418274e+01, 3.98679810e+01, 2.00691166e+01, ...,\n",
       "           2.19682369e+01, 8.58175516e-01, 1.15543013e+01],\n",
       "          [1.72116318e+01, 3.39618492e+01, 2.23455982e+01, ...,\n",
       "           2.07523537e+01, 0.00000000e+00, 1.23097181e+01],\n",
       "          ...,\n",
       "          [2.75080662e+01, 2.78628578e+01, 1.84208393e+01, ...,\n",
       "           5.34887600e+00, 0.00000000e+00, 9.70401382e+00],\n",
       "          [3.83605423e+01, 4.18524704e+01, 1.77951317e+01, ...,\n",
       "           1.69544086e+01, 0.00000000e+00, 1.08945551e+01],\n",
       "          [2.87693100e+01, 7.48023224e+01, 9.44895935e+00, ...,\n",
       "           1.32912874e+01, 0.00000000e+00, 7.39802361e+00]],\n",
       " \n",
       "         [[1.23395882e+01, 1.33175917e+01, 9.15013981e+00, ...,\n",
       "           2.35112801e+01, 0.00000000e+00, 1.07874336e+01],\n",
       "          [2.18298569e+01, 4.43368912e+01, 1.13772850e+01, ...,\n",
       "           8.57201576e+00, 0.00000000e+00, 6.48510885e+00],\n",
       "          [7.25298929e+00, 3.12254353e+01, 1.20898371e+01, ...,\n",
       "           1.47388449e+01, 0.00000000e+00, 1.56760240e+00],\n",
       "          ...,\n",
       "          [1.63072147e+01, 2.24632893e+01, 1.00690737e+01, ...,\n",
       "           9.02592659e+00, 0.00000000e+00, 6.42809534e+00],\n",
       "          [2.37762527e+01, 3.14051723e+01, 1.37715244e+01, ...,\n",
       "           2.59662342e+01, 0.00000000e+00, 6.50846958e+00],\n",
       "          [1.62577648e+01, 6.99504013e+01, 9.34567738e+00, ...,\n",
       "           1.60388622e+01, 0.00000000e+00, 1.47628653e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[7.01089001e+00, 1.54733210e+01, 1.12617416e+01, ...,\n",
       "           2.75962181e+01, 0.00000000e+00, 6.46665716e+00],\n",
       "          [1.79784737e+01, 4.97809944e+01, 8.33815479e+00, ...,\n",
       "           8.53474045e+00, 0.00000000e+00, 8.33971119e+00],\n",
       "          [2.16111355e+01, 4.74415283e+01, 6.95386839e+00, ...,\n",
       "           8.12862206e+00, 0.00000000e+00, 9.15087700e+00],\n",
       "          ...,\n",
       "          [7.04459095e+00, 3.42688904e+01, 6.76838279e-01, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [9.99516869e+00, 3.67953911e+01, 5.98975945e+00, ...,\n",
       "           1.46526976e+01, 0.00000000e+00, 0.00000000e+00],\n",
       "          [9.10818958e+00, 7.65850372e+01, 5.28909969e+00, ...,\n",
       "           1.55815964e+01, 0.00000000e+00, 2.59794784e+00]],\n",
       " \n",
       "         [[1.52518196e+01, 1.58787823e+01, 1.16332273e+01, ...,\n",
       "           2.41329803e+01, 7.83986473e+00, 7.80511236e+00],\n",
       "          [3.53641510e+01, 5.73644600e+01, 8.89159298e+00, ...,\n",
       "           3.75930309e+00, 1.03639469e+01, 9.51848602e+00],\n",
       "          [4.59906158e+01, 6.01116180e+01, 5.54644442e+00, ...,\n",
       "           3.99996328e+00, 1.07321215e+00, 1.61242199e+01],\n",
       "          ...,\n",
       "          [2.56608791e+01, 4.06828842e+01, 0.00000000e+00, ...,\n",
       "           2.06223994e-01, 0.00000000e+00, 4.45300341e+00],\n",
       "          [2.21847820e+01, 4.18528137e+01, 3.52203417e+00, ...,\n",
       "           1.29305925e+01, 3.38998765e-01, 3.16084552e+00],\n",
       "          [1.55230913e+01, 7.59165421e+01, 2.21787333e+00, ...,\n",
       "           6.33905506e+00, 0.00000000e+00, 6.03287792e+00]],\n",
       " \n",
       "         [[4.65857506e+00, 2.71521330e+00, 1.48143702e+01, ...,\n",
       "           2.55821648e+01, 9.97447300e+00, 0.00000000e+00],\n",
       "          [1.29467325e+01, 2.45985432e+01, 1.59905128e+01, ...,\n",
       "           1.00173044e+01, 7.60539198e+00, 0.00000000e+00],\n",
       "          [1.92717876e+01, 2.83213749e+01, 1.13264360e+01, ...,\n",
       "           9.01851082e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          ...,\n",
       "          [1.13914862e+01, 1.57480650e+01, 1.20162134e+01, ...,\n",
       "           1.34264956e+01, 0.00000000e+00, 0.00000000e+00],\n",
       "          [5.53780031e+00, 1.52215147e+01, 1.45818281e+01, ...,\n",
       "           2.07673378e+01, 3.62771726e+00, 0.00000000e+00],\n",
       "          [2.51815271e+00, 3.61804810e+01, 9.78001404e+00, ...,\n",
       "           6.29345942e+00, 4.01501560e+00, 1.75241884e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: id=18483, shape=(1, 30, 30, 256), dtype=float32, numpy=\n",
       " array([[[[33.841827  , 56.21963   , 20.069117  , ..., 32.751858  ,\n",
       "            5.063248  , 11.554301  ],\n",
       "          [18.872576  , 59.710117  , 22.345598  , ..., 20.752354  ,\n",
       "            0.        , 12.309718  ],\n",
       "          [27.437557  , 52.515633  , 16.060474  , ..., 12.629979  ,\n",
       "            0.        ,  5.5165477 ],\n",
       "          ...,\n",
       "          [24.816877  , 57.66377   , 13.586297  , ..., 10.121706  ,\n",
       "            0.        , 12.710885  ],\n",
       "          [29.106077  , 52.940662  , 16.225368  , ...,  8.79083   ,\n",
       "            0.        ,  5.7376237 ],\n",
       "          [47.917     , 65.7791    , 18.42084   , ..., 16.954409  ,\n",
       "            0.        , 11.88813   ]],\n",
       " \n",
       "         [[21.829857  , 47.94284   , 11.377285  , ..., 23.532375  ,\n",
       "            2.9535613 , 10.787434  ],\n",
       "          [ 7.2529893 , 31.225435  , 12.089837  , ..., 17.357422  ,\n",
       "            0.        ,  1.5676024 ],\n",
       "          [23.37233   , 34.627697  ,  7.043937  , ...,  0.        ,\n",
       "            0.        , 11.12894   ],\n",
       "          ...,\n",
       "          [ 8.28517   , 36.192566  ,  6.7437196 , ...,  4.9535036 ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 3.2685924 , 33.065918  ,  6.8001924 , ...,  6.658715  ,\n",
       "            0.        ,  5.702138  ],\n",
       "          [23.776253  , 32.284718  , 13.771524  , ..., 30.413338  ,\n",
       "            0.        ,  6.5084696 ]],\n",
       " \n",
       "         [[12.048854  , 52.791092  , 13.023528  , ..., 20.514257  ,\n",
       "            5.7872825 , 16.825756  ],\n",
       "          [ 7.5963945 , 38.37286   ,  8.127859  , ..., 13.821104  ,\n",
       "            0.        , 14.444589  ],\n",
       "          [ 0.        , 38.25631   ,  3.6535056 , ...,  1.2289941 ,\n",
       "            0.        ,  0.8792129 ],\n",
       "          ...,\n",
       "          [ 1.744697  , 34.663662  ,  0.        , ...,  2.6769257 ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 34.586452  ,  0.        , ...,  4.9807343 ,\n",
       "            0.        ,  0.70796174],\n",
       "          [ 8.808016  , 33.18481   , 10.7500925 , ..., 32.17756   ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[13.889635  , 41.638756  , 10.927079  , ..., 20.743753  ,\n",
       "            3.5698738 ,  3.2925007 ],\n",
       "          [21.50548   , 33.00289   ,  4.370717  , ...,  0.        ,\n",
       "            0.        ,  5.9774194 ],\n",
       "          [21.967516  , 40.00459   ,  0.        , ...,  5.8785663 ,\n",
       "            0.        ,  4.3535185 ],\n",
       "          ...,\n",
       "          [15.2601595 , 30.815388  ,  5.306527  , ...,  0.        ,\n",
       "            0.        ,  6.163912  ],\n",
       "          [21.568779  , 29.42195   ,  4.6172047 , ...,  2.031565  ,\n",
       "            0.        ,  6.4531975 ],\n",
       "          [16.154964  , 25.707651  ,  4.0992537 , ..., 18.956644  ,\n",
       "            0.        ,  1.0602362 ]],\n",
       " \n",
       "         [[ 0.        , 37.385033  , 10.122119  , ..., 28.87931   ,\n",
       "            6.450118  ,  0.        ],\n",
       "          [14.851555  , 34.966965  ,  4.018865  , ...,  9.40722   ,\n",
       "            0.        ,  0.        ],\n",
       "          [17.356375  , 34.769535  ,  0.44539896, ..., 22.097235  ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [13.16791   , 43.59229   ,  0.4558772 , ...,  3.8668082 ,\n",
       "            0.        , 11.823761  ],\n",
       "          [18.114603  , 33.973293  ,  0.77648777, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [15.965009  , 31.173866  ,  8.328984  , ..., 18.183746  ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[35.36415   , 57.36446   , 11.633227  , ..., 27.596218  ,\n",
       "           10.363947  ,  9.518486  ],\n",
       "          [45.990616  , 60.111618  ,  6.9538684 , ..., 15.47903   ,\n",
       "            1.0732121 , 16.12422   ],\n",
       "          [39.464863  , 45.90647   ,  3.718759  , ..., 23.847515  ,\n",
       "            0.        , 14.823119  ],\n",
       "          ...,\n",
       "          [36.06881   , 52.04031   ,  1.3200067 , ...,  8.3287945 ,\n",
       "            0.12072447, 11.083215  ],\n",
       "          [24.32959   , 42.024857  ,  1.7751611 , ...,  0.        ,\n",
       "            0.        ,  8.697504  ],\n",
       "          [25.66088   , 41.852814  ,  5.9897594 , ..., 14.652698  ,\n",
       "            0.33899876,  4.4530034 ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18488, shape=(1, 30, 30, 512), dtype=float32, numpy=\n",
       " array([[[[ 8.853233  ,  1.09322   ,  0.        , ...,  0.        ,\n",
       "           40.652424  ,  0.        ],\n",
       "          [15.055086  ,  4.4756346 ,  0.        , ...,  0.        ,\n",
       "           47.9713    ,  0.        ],\n",
       "          [ 6.689789  ,  6.1350093 ,  0.        , ...,  0.        ,\n",
       "           51.667088  ,  0.        ],\n",
       "          ...,\n",
       "          [15.263813  , 18.150875  ,  0.46932438, ...,  0.        ,\n",
       "           61.991314  ,  0.        ],\n",
       "          [ 0.        , 18.862743  ,  0.        , ...,  0.        ,\n",
       "           65.392136  ,  0.        ],\n",
       "          [ 2.3915062 , 14.911917  ,  6.3932486 , ...,  0.        ,\n",
       "           57.8528    ,  0.        ]],\n",
       " \n",
       "         [[13.492816  , 15.46912   ,  0.        , ...,  0.        ,\n",
       "           31.800549  ,  0.        ],\n",
       "          [ 1.8220906 , 25.80464   ,  0.        , ...,  0.        ,\n",
       "           27.6891    ,  0.        ],\n",
       "          [ 0.        , 22.836792  ,  0.46585974, ...,  0.        ,\n",
       "           21.259455  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 34.320538  ,  7.2554827 , ...,  0.        ,\n",
       "           22.29652   ,  0.        ],\n",
       "          [ 0.        , 30.725496  ,  0.        , ...,  0.        ,\n",
       "           22.382544  ,  0.        ],\n",
       "          [ 0.        , 24.107548  , 11.238886  , ...,  0.        ,\n",
       "           21.733383  ,  0.        ]],\n",
       " \n",
       "         [[10.11858   , 13.469688  ,  0.        , ...,  0.        ,\n",
       "           19.072512  ,  8.797345  ],\n",
       "          [ 8.031363  , 26.413223  ,  0.        , ...,  0.        ,\n",
       "           18.096992  ,  0.        ],\n",
       "          [ 0.        , 29.317003  ,  0.        , ...,  0.        ,\n",
       "           20.328415  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 30.867342  ,  0.        , ...,  0.        ,\n",
       "           11.75627   ,  0.        ],\n",
       "          [ 3.0051806 , 27.200766  ,  0.        , ...,  0.        ,\n",
       "           12.337868  ,  0.        ],\n",
       "          [ 0.        , 23.004316  ,  3.372816  , ...,  0.        ,\n",
       "           12.291669  ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.6752074 , 14.982353  ,  0.        , ...,  0.        ,\n",
       "            8.642948  ,  9.457803  ],\n",
       "          [ 0.        , 29.585007  ,  0.        , ...,  0.        ,\n",
       "           12.385933  ,  0.        ],\n",
       "          [ 0.        , 20.30012   ,  0.        , ...,  0.        ,\n",
       "           14.823439  ,  0.        ],\n",
       "          ...,\n",
       "          [ 1.8801144 , 28.598074  ,  2.4564822 , ...,  0.        ,\n",
       "           18.076525  ,  0.        ],\n",
       "          [ 5.1278157 , 29.415474  ,  0.        , ...,  0.        ,\n",
       "           19.632605  ,  0.        ],\n",
       "          [ 0.        , 30.180136  ,  8.743277  , ...,  0.        ,\n",
       "           21.676865  ,  0.        ]],\n",
       " \n",
       "         [[10.325024  , 12.292977  ,  0.        , ...,  0.        ,\n",
       "           15.092886  ,  2.2901223 ],\n",
       "          [ 0.        , 23.080004  ,  0.        , ...,  0.        ,\n",
       "           22.629465  ,  0.        ],\n",
       "          [ 0.        , 14.550242  ,  0.        , ...,  0.        ,\n",
       "           17.50783   ,  0.        ],\n",
       "          ...,\n",
       "          [12.121844  , 26.057262  ,  0.        , ...,  0.        ,\n",
       "           23.142578  ,  0.        ],\n",
       "          [ 8.5459385 , 24.222216  ,  0.        , ...,  0.        ,\n",
       "           22.478241  ,  0.        ],\n",
       "          [ 0.        , 27.553902  ,  7.880066  , ...,  0.        ,\n",
       "           23.564333  ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , 27.24128   ,  5.3919916 , ...,  0.        ,\n",
       "            0.        , 12.756582  ],\n",
       "          [ 0.        , 40.06439   , 19.782835  , ...,  0.        ,\n",
       "            0.        ,  5.842604  ],\n",
       "          [ 0.52194077, 34.73398   ,  9.1896925 , ...,  0.        ,\n",
       "            0.        ,  4.6735845 ],\n",
       "          ...,\n",
       "          [15.434363  , 43.75197   , 16.77172   , ...,  0.        ,\n",
       "            0.        ,  6.7476516 ],\n",
       "          [ 4.3548417 , 41.903446  , 16.657602  , ...,  0.        ,\n",
       "            0.        ,  6.3166366 ],\n",
       "          [ 0.        , 34.644806  , 25.465563  , ...,  0.        ,\n",
       "            0.        ,  6.763342  ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18493, shape=(1, 30, 30, 512), dtype=float32, numpy=\n",
       " array([[[[14.463595  ,  0.        ,  0.        , ...,  2.033117  ,\n",
       "           20.857233  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           21.554815  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  7.252192  ,\n",
       "           17.219246  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  6.836955  ,\n",
       "           13.31784   ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  3.7355075 ,\n",
       "           13.573477  ,  5.210315  ],\n",
       "          [ 0.        ,  0.        ,  1.6409781 , ...,  7.949746  ,\n",
       "           15.971098  , 21.564905  ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ..., 19.659042  ,\n",
       "           21.540482  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 13.477976  ,\n",
       "           24.775873  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 36.345127  ,\n",
       "           14.506357  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 21.238823  ,\n",
       "           12.278893  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 26.735882  ,\n",
       "           11.6413145 ,  4.4886723 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 32.533405  ,\n",
       "           19.869144  , 18.98134   ]],\n",
       " \n",
       "         [[ 3.2154384 ,  0.        ,  0.        , ..., 27.134863  ,\n",
       "            2.18339   ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 17.63383   ,\n",
       "            2.2574005 ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 26.23409   ,\n",
       "            2.5215595 ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 22.777536  ,\n",
       "           10.743546  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 29.608507  ,\n",
       "            3.5556726 ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 37.77956   ,\n",
       "           16.765783  ,  4.1935153 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.7125204 ,  0.        ,  0.        , ..., 13.236236  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  8.758819  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  2.07764   ,\n",
       "            5.865959  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 16.411818  ,\n",
       "            3.2928073 ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ..., 19.697815  ,\n",
       "            7.669322  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 21.0281    ,\n",
       "            9.9616    ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 10.475346  ,\n",
       "           30.346428  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  2.9572642 ,\n",
       "            0.5842448 ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  2.823601  ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 19.189245  ,\n",
       "            2.595924  ,  2.4970336 ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ..., 10.9487915 ,\n",
       "            7.157193  ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  7.0129786 ,\n",
       "           14.39106   ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  2.1117911 ,\n",
       "           28.553709  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  1.9960121 ,\n",
       "            3.042553  ,  8.163333  ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  5.1336412 ,\n",
       "            0.        ,  9.699812  ],\n",
       "          [ 0.        ,  0.        ,  0.        , ..., 15.708767  ,\n",
       "            0.04876197,  8.802132  ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18498, shape=(1, 30, 30, 512), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  0.14584203, 10.545379  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  2.0251439 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        , 16.167805  , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , 30.633026  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 29.956842  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 31.109503  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 34.49632   ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 35.739193  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 33.079865  ,  9.445875  , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , 29.309011  ,  0.        , ...,  0.        ,\n",
       "            4.1943703 ,  0.        ],\n",
       "          [ 0.        , 25.438452  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 27.317148  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 28.749575  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 32.95323   ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 34.938156  ,  6.830769  , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.        , 24.350355  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 24.082487  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 28.937489  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 12.588457  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 24.158173  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 28.993834  ,  4.625773  , ...,  0.        ,\n",
       "            3.1864545 ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , 28.641636  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 22.539425  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 28.506392  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 22.66418   ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 35.300327  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 37.54682   ,  1.9189811 , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , 32.32528   ,  0.        , ...,  0.        ,\n",
       "           13.279259  ,  0.        ],\n",
       "          [ 0.        , 31.15142   ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 28.957445  ,  0.        , ...,  0.        ,\n",
       "            3.259972  ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        , 29.02469   ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 37.033268  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 39.723614  ,  0.        , ...,  0.        ,\n",
       "            3.1984353 ,  0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18503, shape=(1, 30, 30, 512), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  7.1378765 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  4.689667  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  6.1442223 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  7.101684  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  9.167546  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        , 12.072103  ,  0.61044073, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.28388107,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.218091  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.13560253,  3.9407287 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 1.4161221 , 16.503672  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.16714586,  1.3308299 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 6.1298065 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 1.3194109 ,  0.49197447,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.09470633],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 1.4801128 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 2.5702333 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            4.934328  ,  0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18504, shape=(1, 15, 15, 512), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  7.1378765 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  6.4529777 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  9.429563  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  8.309199  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  7.101684  ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 1.4161221 , 16.503672  ,  0.61044073, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.1079557 ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.16714586,  1.3308299 ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 1.0748311 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 3.1317306 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  1.1520002 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 6.1298065 ,  0.49197447,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.09470633],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 2.5702333 ,  0.        ,  0.        , ...,  0.        ,\n",
       "            4.934328  ,  0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18509, shape=(1, 15, 15, 512), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.        , 3.867519  , ..., 1.7072476 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 1.1359657 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.5510635 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 3.2804513 , ..., 1.2421957 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 1.2030586 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.431054  ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.23025392, 0.        , 1.3963246 , ..., 1.1675911 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.90607077,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 1.0300918 ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.8896225 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.48346633,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 2.4102252 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.18719316,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[2.5886443 , 0.        , 4.1239405 , ..., 0.22174199,\n",
       "           0.        , 0.        ],\n",
       "          [0.00648242, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 1.2370667 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.10917474, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18514, shape=(1, 15, 15, 512), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.        , 4.594957  , ..., 0.        ,\n",
       "           2.9944417 , 1.0427501 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           4.072469  , 0.08615309],\n",
       "          [0.        , 0.        , 0.05076036, ..., 0.        ,\n",
       "           4.2586675 , 0.03886183],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           4.2990675 , 0.26142865],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           5.319435  , 0.36275303],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           4.1634164 , 0.10967834]],\n",
       " \n",
       "         [[0.        , 0.        , 4.4794054 , ..., 0.        ,\n",
       "           0.        , 0.90621424],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.09211075, 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.2322506 , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           1.1448954 , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           1.3368843 , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.53862727, 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 4.254574  , ..., 0.        ,\n",
       "           0.1726158 , 1.3983265 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.5746249 , 0.62263745],\n",
       "          [0.        , 0.        , 0.        , ..., 0.92764044,\n",
       "           0.5614363 , 0.10575099],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 1.229157  ,\n",
       "           1.0440856 , 0.18980224],\n",
       "          [0.        , 0.        , 0.        , ..., 0.58154494,\n",
       "           1.1838887 , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.35680032,\n",
       "           0.39964277, 0.7951892 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 3.547761  , ..., 0.        ,\n",
       "           0.        , 2.1675193 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 2.1146865 ],\n",
       "          [0.        , 0.        , 0.05852361, ..., 0.21669105,\n",
       "           0.        , 1.594114  ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.9150305 ,\n",
       "           0.3336155 , 0.60342634],\n",
       "          [0.        , 0.        , 0.        , ..., 0.22017059,\n",
       "           0.8296112 , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.7115878 , 0.580019  ]],\n",
       " \n",
       "         [[0.        , 0.        , 3.750391  , ..., 0.        ,\n",
       "           0.        , 1.9892906 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 1.34442   ],\n",
       "          [0.29446617, 0.        , 0.3642683 , ..., 0.        ,\n",
       "           0.        , 0.77091986],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.30122718, 0.0790024 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.7279366 , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           1.009544  , 0.03838806]],\n",
       " \n",
       "         [[0.        , 0.        , 3.4242637 , ..., 0.        ,\n",
       "           0.        , 1.8979025 ],\n",
       "          [0.        , 0.        , 0.24915226, ..., 0.        ,\n",
       "           0.        , 1.0667024 ],\n",
       "          [0.        , 0.        , 0.57663214, ..., 0.27088308,\n",
       "           0.        , 0.67332256],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.17518806,\n",
       "           0.        , 0.07360612],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.97515965, ..., 0.        ,\n",
       "           0.        , 0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18519, shape=(1, 15, 15, 512), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.        , 0.10928459, ..., 0.33020854,\n",
       "           0.        , 0.07882824],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.09469379],\n",
       "          [0.        , 0.        , 0.2110065 , ..., 0.0584341 ,\n",
       "           0.        , 0.23340753],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.02215272, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.1731715 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.2929663 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.6461369 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.21992773],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.19856443]],\n",
       " \n",
       "         [[0.        , 0.        , 0.78929824, ..., 0.        ,\n",
       "           0.        , 0.45675433],\n",
       "          [0.        , 0.        , 0.33453816, ..., 0.        ,\n",
       "           0.        , 0.40116772],\n",
       "          [0.        , 0.        , 0.66249496, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.6974393 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 1.0191885 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.3433304 , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 1.0780818 , ..., 0.        ,\n",
       "           0.        , 0.45632225],\n",
       "          [0.        , 0.        , 0.79788154, ..., 0.        ,\n",
       "           0.        , 0.12562972],\n",
       "          [0.        , 0.        , 1.1450841 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.43950462, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.737694  , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.13393888, ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 1.1862829 , ..., 0.1662722 ,\n",
       "           0.        , 0.20587958],\n",
       "          [0.        , 0.        , 1.1289184 , ..., 0.        ,\n",
       "           0.        , 0.0220115 ],\n",
       "          [0.        , 0.        , 1.4626055 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.7334565 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 1.1405385 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.23268834, ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.4278214 , ..., 0.6867745 ,\n",
       "           0.4769924 , 0.5281861 ],\n",
       "          [0.0068239 , 0.        , 0.06217091, ..., 0.20824957,\n",
       "           0.53342557, 0.66845953],\n",
       "          [0.0142449 , 0.        , 0.3717215 , ..., 0.09922184,\n",
       "           0.09960788, 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.00616969, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.1792686 , ..., 0.        ,\n",
       "           0.01665431, 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.18951696,\n",
       "           0.39000586, 0.3712538 ]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18524, shape=(1, 15, 15, 512), dtype=float32, numpy=\n",
       " array([[[[6.3578290e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 9.8385113e-01, 0.0000000e+00],\n",
       "          [8.0989265e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.1235162e-01, 0.0000000e+00],\n",
       "          [5.3630471e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.2986188e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [4.0176633e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.4031794e-01, 0.0000000e+00],\n",
       "          [4.5445958e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.9418029e-01, 0.0000000e+00],\n",
       "          [3.4001547e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.7140877e-01, 0.0000000e+00]],\n",
       " \n",
       "         [[4.0805280e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 9.2051393e-01, 0.0000000e+00],\n",
       "          [1.3369322e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 4.2827299e-01, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 4.9863717e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 3.9539152e-01, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.8915731e-01, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 4.6325022e-01, 0.0000000e+00]],\n",
       " \n",
       "         [[6.9016933e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.1720626e+00, 0.0000000e+00],\n",
       "          [1.1245394e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.2021145e-01, 0.0000000e+00],\n",
       "          [1.5503168e-03, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.5229460e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.2214848e-01, 0.0000000e+00],\n",
       "          [1.2503779e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.4199153e-01, 0.0000000e+00],\n",
       "          [1.1843592e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.8324763e-01, 0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.1585355e-03, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.3152378e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.8127575e-01, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 8.9504331e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.0406526e-01, 0.0000000e+00],\n",
       "          [1.2485379e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.5967709e-01, 0.0000000e+00],\n",
       "          [1.1716890e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.6677614e-01, 0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.2026722e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 7.0933461e-01, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 9.5976770e-01, 0.0000000e+00],\n",
       "          ...,\n",
       "          [1.6050458e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.3644004e-01, 0.0000000e+00],\n",
       "          [1.5095627e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.1030672e-01, 0.0000000e+00],\n",
       "          [1.4311630e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.2272340e-01, 0.0000000e+00]],\n",
       " \n",
       "         [[2.4655432e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.1857527e+00, 0.0000000e+00],\n",
       "          [1.5223324e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 9.3180925e-01, 0.0000000e+00],\n",
       "          [1.5665340e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 1.0488403e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [3.6113814e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.4055789e-01, 0.0000000e+00],\n",
       "          [4.3035129e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 5.6648833e-01, 0.0000000e+00],\n",
       "          [3.6862543e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 6.4249939e-01, 0.0000000e+00]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=18525, shape=(1, 7, 7, 512), dtype=float32, numpy=\n",
       " array([[[[8.09892654e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 9.83851135e-01, 0.00000000e+00],\n",
       "          [5.90553939e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.29861879e-01, 0.00000000e+00],\n",
       "          [7.14442194e-01, 0.00000000e+00, 1.55571699e-02, ...,\n",
       "           0.00000000e+00, 7.43085325e-01, 0.00000000e+00],\n",
       "          ...,\n",
       "          [8.55588317e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.04575920e-01, 0.00000000e+00],\n",
       "          [6.83749199e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.11578631e-01, 0.00000000e+00],\n",
       "          [4.54459578e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.40317941e-01, 0.00000000e+00]],\n",
       " \n",
       "         [[1.12453938e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.26998913e+00, 0.00000000e+00],\n",
       "          [1.79381371e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.86307395e-01, 0.00000000e+00],\n",
       "          [2.82027096e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.45197260e-01, 0.00000000e+00],\n",
       "          ...,\n",
       "          [3.36012155e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.74711454e-01, 0.00000000e+00],\n",
       "          [2.37928241e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.28546703e-01, 0.00000000e+00],\n",
       "          [1.25037789e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.22148478e-01, 0.00000000e+00]],\n",
       " \n",
       "         [[1.03897870e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.25644374e+00, 0.00000000e+00],\n",
       "          [2.19901860e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.52847695e-01, 0.00000000e+00],\n",
       "          [2.73794502e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.59339595e-01, 0.00000000e+00],\n",
       "          ...,\n",
       "          [3.43885869e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.54918420e-01, 0.00000000e+00],\n",
       "          [4.58320826e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.79607177e-01, 0.00000000e+00],\n",
       "          [3.27883393e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.16261864e-01, 0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.01412654e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.22758496e+00, 0.00000000e+00],\n",
       "          [1.25708699e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.43760467e-01, 0.00000000e+00],\n",
       "          [2.96247810e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 8.63401890e-01, 0.00000000e+00],\n",
       "          ...,\n",
       "          [3.73478055e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.81047642e-01, 0.00000000e+00],\n",
       "          [4.41037655e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 6.86904907e-01, 0.00000000e+00],\n",
       "          [3.83917332e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.42935300e-01, 0.00000000e+00]],\n",
       " \n",
       "         [[1.12977386e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.25116932e+00, 0.00000000e+00],\n",
       "          [1.48333490e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.45018184e-01, 0.00000000e+00],\n",
       "          [3.27596873e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 9.34175014e-01, 0.00000000e+00],\n",
       "          ...,\n",
       "          [3.62524927e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 9.00676727e-01, 0.00000000e+00],\n",
       "          [4.03675288e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 6.77481830e-01, 0.00000000e+00],\n",
       "          [3.11384469e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 6.87045693e-01, 0.00000000e+00]],\n",
       " \n",
       "         [[1.15853548e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.31523776e+00, 0.00000000e+00],\n",
       "          [7.23522902e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 9.59767699e-01, 0.00000000e+00],\n",
       "          [1.49060547e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.04430068e+00, 0.00000000e+00],\n",
       "          ...,\n",
       "          [2.46573478e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 1.05022228e+00, 0.00000000e+00],\n",
       "          [2.34845787e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.98935473e-01, 0.00000000e+00],\n",
       "          [1.50956273e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 7.04065263e-01, 0.00000000e+00]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: id=18527, shape=(1, 25088), dtype=float32, numpy=\n",
       " array([[0.80989265, 0.        , 0.        , ..., 0.        , 0.70406526,\n",
       "         0.        ]], dtype=float32)>,\n",
       " <tf.Tensor: id=18532, shape=(1, 4096), dtype=float32, numpy=\n",
       " array([[0.       , 1.7865516, 0.       , ..., 0.       , 2.798893 ,\n",
       "         1.2226701]], dtype=float32)>,\n",
       " <tf.Tensor: id=18537, shape=(1, 4096), dtype=float32, numpy=\n",
       " array([[0.5475817 , 0.        , 0.46086112, ..., 0.        , 0.563346  ,\n",
       "         0.        ]], dtype=float32)>,\n",
       " <tf.Tensor: id=18542, shape=(1, 1000), dtype=float32, numpy=\n",
       " array([[1.94834050e-04, 1.29728217e-03, 6.70577050e-04, 1.58320740e-03,\n",
       "         2.26117205e-03, 2.01928243e-03, 7.69310724e-03, 1.74035580e-04,\n",
       "         2.68172385e-04, 2.27891287e-04, 5.94816636e-04, 2.87930685e-04,\n",
       "         3.90677975e-04, 7.90079823e-04, 3.36291851e-04, 3.30605137e-04,\n",
       "         6.62452949e-04, 3.56848643e-04, 7.10836030e-04, 9.90338624e-04,\n",
       "         1.34683249e-03, 9.22901905e-04, 6.88474975e-04, 5.27195400e-04,\n",
       "         1.40894437e-04, 2.52340134e-04, 1.14198646e-03, 1.07498025e-03,\n",
       "         2.68142845e-04, 4.19074530e-03, 3.53390351e-04, 3.98805889e-04,\n",
       "         4.11062152e-04, 1.42699608e-03, 9.38238925e-04, 4.94338106e-04,\n",
       "         1.21573440e-03, 3.78117315e-04, 2.44191731e-03, 2.72974343e-04,\n",
       "         7.17923045e-04, 6.75861142e-04, 9.83837643e-04, 5.55668317e-04,\n",
       "         8.31970247e-04, 1.82811543e-03, 8.91669129e-04, 6.86099112e-04,\n",
       "         5.10620128e-04, 5.75714628e-04, 9.81546240e-04, 3.37275938e-04,\n",
       "         2.52805767e-03, 2.47654878e-03, 8.15036241e-04, 2.94255733e-04,\n",
       "         1.36066915e-03, 2.18603673e-04, 1.08169317e-02, 3.87942768e-04,\n",
       "         1.35078991e-03, 9.94695816e-04, 1.02095469e-03, 9.00318963e-04,\n",
       "         2.51556491e-03, 1.59675640e-03, 2.59790011e-03, 1.05353864e-03,\n",
       "         1.22334994e-03, 2.27297889e-03, 1.46500883e-03, 2.12923181e-03,\n",
       "         5.97129343e-04, 1.14966067e-03, 4.73430468e-04, 4.59690439e-03,\n",
       "         1.29064277e-03, 2.12140498e-03, 8.46161321e-03, 4.93970187e-03,\n",
       "         1.05653459e-03, 4.18317597e-03, 5.53916907e-04, 7.10038061e-04,\n",
       "         2.96927377e-04, 1.63904938e-03, 1.40977802e-03, 2.15078727e-03,\n",
       "         2.42611932e-04, 2.37453007e-03, 7.42650591e-05, 3.89661582e-04,\n",
       "         9.28333669e-04, 1.68377883e-04, 7.42804492e-04, 1.43897458e-04,\n",
       "         4.20263590e-04, 2.36060456e-04, 9.17660829e-04, 6.47310284e-04,\n",
       "         2.91035627e-04, 2.69452255e-04, 3.15654499e-04, 1.88583415e-03,\n",
       "         2.58970482e-04, 8.55464532e-05, 6.19152794e-04, 6.06369169e-04,\n",
       "         4.95971122e-04, 5.11296385e-04, 1.98346825e-04, 3.66367167e-03,\n",
       "         1.14952587e-03, 4.94741194e-04, 5.65289054e-04, 6.93077891e-05,\n",
       "         1.60193376e-04, 1.37071242e-03, 3.59070982e-04, 2.14956308e-04,\n",
       "         1.98252685e-03, 7.77204186e-05, 1.14203373e-04, 9.50573667e-05,\n",
       "         1.20760326e-03, 1.15798437e-03, 1.94208929e-03, 1.00242510e-03,\n",
       "         1.16978469e-03, 9.05035005e-04, 2.27741068e-04, 8.66841292e-04,\n",
       "         2.07550591e-03, 3.28750000e-04, 8.35034356e-04, 2.70362303e-04,\n",
       "         1.77688969e-04, 1.17064314e-03, 2.44394876e-03, 5.92438038e-04,\n",
       "         1.70775061e-03, 1.98437180e-03, 1.49138970e-03, 8.23015231e-04,\n",
       "         4.68032435e-04, 5.78587234e-04, 1.73628924e-03, 1.39537791e-04,\n",
       "         1.90527193e-04, 1.99205289e-03, 6.60638034e-04, 1.26293709e-03,\n",
       "         2.61456124e-04, 3.86622502e-03, 1.69104536e-03, 1.33489969e-03,\n",
       "         6.39922509e-04, 9.07558308e-04, 5.50765486e-04, 2.16104265e-04,\n",
       "         2.79939210e-04, 6.56237011e-04, 1.32984854e-03, 5.57765248e-04,\n",
       "         3.43551132e-04, 9.18454534e-05, 7.65605480e-04, 1.77107242e-04,\n",
       "         4.29431937e-04, 4.13850415e-04, 6.65719446e-04, 1.27971999e-03,\n",
       "         1.71080185e-03, 6.85843348e-04, 4.81769122e-04, 1.57401781e-04,\n",
       "         3.30999814e-04, 2.19328183e-04, 1.00635120e-03, 7.91306258e-04,\n",
       "         7.42895354e-04, 6.79984631e-04, 5.38834371e-04, 8.34237871e-05,\n",
       "         4.35978087e-04, 4.19329561e-04, 3.09736672e-04, 2.57971056e-04,\n",
       "         3.59430589e-04, 2.79722939e-04, 1.09951978e-03, 1.69326333e-04,\n",
       "         1.18465605e-03, 2.37491287e-04, 4.10166016e-04, 4.25303704e-04,\n",
       "         5.07560966e-04, 1.17215517e-04, 1.03172824e-04, 6.54792704e-04,\n",
       "         2.29568410e-04, 1.44656762e-04, 9.38373152e-04, 4.07783268e-03,\n",
       "         1.65872741e-03, 8.70575968e-05, 7.14205235e-05, 6.15024648e-04,\n",
       "         6.10675255e-04, 1.55527389e-03, 2.45071918e-04, 3.05348192e-04,\n",
       "         8.39205633e-04, 1.52503111e-04, 1.30764733e-04, 6.69916975e-04,\n",
       "         3.46156652e-04, 5.30542864e-04, 4.90473583e-04, 2.60333531e-04,\n",
       "         1.09834386e-04, 7.59587274e-05, 1.55587471e-03, 3.67225410e-04,\n",
       "         8.76349441e-05, 2.61453271e-04, 1.84114266e-04, 1.80928342e-04,\n",
       "         4.12236579e-04, 1.04814407e-03, 5.88292605e-04, 2.50124402e-04,\n",
       "         2.50457349e-04, 1.79231167e-04, 1.96364024e-04, 1.42127989e-04,\n",
       "         2.70639342e-04, 9.99620184e-04, 5.55560866e-04, 4.48611303e-04,\n",
       "         1.87982107e-04, 2.49415520e-04, 9.61493526e-04, 2.89727846e-04,\n",
       "         7.12402471e-05, 1.23509089e-03, 3.12307733e-04, 3.84998304e-04,\n",
       "         4.66485071e-04, 5.06065902e-04, 1.39849924e-03, 5.13980398e-04,\n",
       "         1.23503080e-04, 5.08055673e-04, 7.89744954e-04, 8.56867628e-05,\n",
       "         1.29098320e-04, 2.48489715e-03, 6.09781221e-03, 1.13799376e-03,\n",
       "         3.83612758e-04, 3.31335090e-04, 1.06391657e-04, 1.23897335e-03,\n",
       "         5.16223372e-04, 1.42803893e-03, 5.26238931e-04, 2.47631076e-04,\n",
       "         3.72506940e-04, 2.20161644e-04, 1.10054761e-03, 1.34542061e-04,\n",
       "         4.73349472e-04, 9.52846603e-04, 3.39547638e-04, 2.42490161e-04,\n",
       "         6.12682081e-04, 5.38981985e-04, 4.04969527e-04, 3.95471882e-03,\n",
       "         3.79662029e-04, 4.55334695e-04, 6.78644399e-04, 3.03596281e-03,\n",
       "         3.33765824e-03, 7.75817549e-04, 5.44355484e-04, 1.13083539e-03,\n",
       "         2.62219866e-04, 5.28551347e-04, 9.85213119e-05, 3.80862941e-04,\n",
       "         1.06963918e-04, 2.00641429e-04, 9.40260579e-05, 6.62057064e-05,\n",
       "         1.32219994e-03, 2.51768390e-04, 8.19200708e-04, 1.07203913e-03,\n",
       "         3.73427640e-04, 1.26228621e-03, 4.11593704e-04, 4.05794533e-04,\n",
       "         2.90562224e-04, 8.58867774e-04, 5.72297198e-04, 4.76164016e-04,\n",
       "         6.34998607e-04, 9.26625144e-05, 1.95983541e-03, 8.53060745e-04,\n",
       "         1.48181152e-03, 2.01063696e-03, 9.32240207e-03, 1.10816059e-03,\n",
       "         7.16349517e-04, 5.40236593e-04, 3.85654182e-03, 9.33612813e-04,\n",
       "         4.73863212e-04, 8.28340853e-05, 1.88523394e-04, 5.20968242e-05,\n",
       "         2.65608425e-04, 7.50269755e-05, 1.65015445e-04, 6.62571227e-04,\n",
       "         2.63063732e-04, 5.58081141e-04, 1.23781420e-03, 1.80984917e-03,\n",
       "         2.55627674e-03, 3.59626417e-03, 4.37407143e-04, 2.52285536e-04,\n",
       "         3.25142988e-04, 3.34489770e-04, 4.62783122e-04, 3.45930093e-05,\n",
       "         1.16121962e-04, 3.71397386e-04, 1.53271278e-04, 2.83907575e-04,\n",
       "         4.42666176e-04, 1.43166093e-04, 3.45465407e-04, 1.17864547e-04,\n",
       "         2.50672660e-04, 4.03349346e-04, 8.58557760e-04, 4.04463906e-04,\n",
       "         1.85076264e-04, 4.53544373e-04, 4.45907062e-04, 1.75621331e-04,\n",
       "         2.52182037e-03, 5.05359843e-04, 2.28761602e-03, 3.28983134e-03,\n",
       "         6.22177322e-04, 3.89534340e-04, 9.59365570e-04, 1.26173894e-03,\n",
       "         1.55178219e-04, 1.63286706e-04, 1.20832177e-04, 2.49103963e-04,\n",
       "         1.52817942e-04, 7.06688661e-05, 1.84284494e-04, 3.91845679e-04,\n",
       "         3.12326621e-04, 3.37664067e-04, 8.67504161e-04, 1.20648925e-04,\n",
       "         2.99489038e-04, 5.91404212e-04, 3.62756778e-04, 1.12702597e-04,\n",
       "         4.70969244e-04, 9.85993320e-05, 3.07071256e-04, 3.18068924e-04,\n",
       "         8.45497198e-05, 2.65405746e-04, 4.40954667e-04, 1.46250313e-04,\n",
       "         1.50435662e-04, 3.86635133e-04, 3.62950028e-04, 8.46905459e-04,\n",
       "         7.40986652e-05, 2.70410907e-04, 5.73479803e-04, 1.09518750e-03,\n",
       "         1.60355616e-04, 6.56196324e-04, 2.01554023e-04, 4.14065173e-04,\n",
       "         2.10052858e-05, 1.38562056e-04, 2.31867481e-04, 8.97475911e-05,\n",
       "         8.11331556e-04, 2.26144493e-03, 7.59923860e-05, 2.01254297e-04,\n",
       "         5.75342565e-05, 4.03949700e-04, 8.37769403e-05, 7.89504324e-04,\n",
       "         6.38153637e-04, 4.23179619e-04, 3.13034107e-04, 2.00033013e-04,\n",
       "         4.77106572e-04, 1.21682591e-03, 4.55242535e-03, 1.87368561e-02,\n",
       "         5.51276666e-04, 7.00539909e-04, 2.19687732e-04, 1.89808750e-04,\n",
       "         1.88838196e-04, 8.30945137e-05, 9.24905820e-04, 3.01646185e-04,\n",
       "         1.74488610e-04, 8.76144273e-04, 1.59113872e-04, 7.31184287e-03,\n",
       "         3.76550684e-04, 1.04859844e-03, 5.98039757e-03, 3.58832767e-03,\n",
       "         2.25850061e-04, 3.74000723e-04, 1.35464559e-03, 8.03843068e-05,\n",
       "         3.40475846e-04, 9.28822730e-04, 2.54848186e-04, 5.03131049e-03,\n",
       "         8.06894532e-05, 2.06204597e-04, 4.89737885e-03, 3.38438927e-04,\n",
       "         5.09952835e-04, 6.84156257e-05, 7.85930373e-04, 3.54144082e-04,\n",
       "         1.27447618e-03, 5.08135301e-04, 1.41108030e-04, 2.22211657e-03,\n",
       "         8.41723464e-04, 3.65404791e-04, 9.60071047e-04, 1.61322893e-03,\n",
       "         3.49045469e-04, 6.25612796e-04, 1.59621739e-03, 5.83863293e-04,\n",
       "         4.39839991e-04, 1.25908339e-03, 3.61014070e-04, 4.26496226e-05,\n",
       "         1.21330384e-04, 3.64153995e-04, 8.17585562e-04, 2.60104483e-04,\n",
       "         5.42597663e-05, 1.74676417e-03, 5.52085869e-04, 6.40783459e-04,\n",
       "         4.09919630e-05, 1.32152418e-04, 5.81706408e-03, 2.14926171e-04,\n",
       "         3.75339063e-03, 1.34511897e-03, 2.47233576e-04, 3.99011333e-05,\n",
       "         2.03381307e-04, 1.60948746e-03, 9.31812829e-05, 2.06309254e-03,\n",
       "         4.40502830e-04, 2.34477659e-04, 2.02602605e-04, 2.10473954e-04,\n",
       "         1.60983019e-03, 3.16164544e-04, 3.82494909e-04, 7.17271178e-04,\n",
       "         5.42412861e-04, 1.19137432e-04, 2.29444093e-04, 2.23832461e-03,\n",
       "         4.47741942e-04, 1.43504221e-04, 6.71791611e-04, 4.55750444e-04,\n",
       "         1.11192162e-03, 4.40517731e-04, 2.29318204e-04, 3.87062522e-04,\n",
       "         1.28618802e-03, 5.02430157e-05, 3.86812142e-04, 8.28968696e-05,\n",
       "         3.33148229e-04, 1.70529689e-04, 1.20694378e-04, 5.46236581e-04,\n",
       "         3.61407921e-03, 2.68136471e-04, 2.77760177e-04, 1.58807950e-03,\n",
       "         5.63236699e-03, 6.16302365e-04, 1.02823476e-04, 5.53830236e-04,\n",
       "         3.02200904e-04, 3.44960688e-04, 6.21642685e-04, 2.17279303e-04,\n",
       "         6.88146567e-04, 4.20077285e-03, 5.33980841e-04, 4.99843212e-04,\n",
       "         8.37793224e-04, 6.08476694e-04, 3.20273591e-03, 4.73498891e-04,\n",
       "         3.31256560e-05, 2.51830963e-04, 1.33521424e-03, 8.78799998e-04,\n",
       "         2.67189054e-04, 3.59791680e-04, 1.63931854e-03, 2.52200960e-04,\n",
       "         1.43085839e-04, 5.14744688e-03, 1.80319417e-04, 3.49426482e-05,\n",
       "         1.68122584e-04, 2.59952340e-02, 7.82340867e-05, 3.02891503e-03,\n",
       "         1.74923392e-04, 1.01258617e-03, 1.22141954e-03, 7.47791346e-05,\n",
       "         3.82209034e-03, 4.22798999e-04, 8.09281075e-04, 7.55861169e-04,\n",
       "         2.98973959e-04, 1.32019966e-04, 6.35337492e-05, 1.49318995e-03,\n",
       "         5.77496423e-04, 2.37541448e-04, 1.10523884e-04, 4.48233681e-04,\n",
       "         2.39270084e-04, 1.04753635e-04, 8.72958510e-04, 9.78355238e-05,\n",
       "         7.93562329e-04, 2.04695520e-04, 1.38195918e-03, 7.14015550e-05,\n",
       "         1.32368863e-04, 1.11013756e-03, 2.50308367e-04, 1.85055076e-04,\n",
       "         8.34449893e-05, 3.24965367e-05, 1.02510159e-04, 8.67750321e-04,\n",
       "         5.65989001e-04, 8.83062312e-04, 2.54559389e-04, 8.41934350e-04,\n",
       "         1.80724857e-03, 1.98753993e-03, 3.15337500e-04, 7.79272290e-03,\n",
       "         9.67743108e-04, 5.40814595e-04, 1.16204879e-04, 7.95733649e-05,\n",
       "         8.69893178e-04, 3.99683544e-04, 3.15802346e-04, 4.97210771e-04,\n",
       "         1.63953507e-03, 1.85440492e-03, 1.74978704e-04, 1.29202948e-04,\n",
       "         1.50457339e-03, 2.49027857e-03, 1.49837672e-03, 1.99465911e-04,\n",
       "         1.91224564e-04, 2.33159473e-04, 2.74147443e-03, 6.24302833e-04,\n",
       "         4.22673838e-05, 5.23636874e-04, 1.33691196e-04, 8.43388145e-04,\n",
       "         6.76659751e-04, 6.61913655e-04, 3.97809548e-03, 1.89820351e-03,\n",
       "         2.54198397e-03, 1.90076389e-04, 2.37103971e-03, 3.00679449e-03,\n",
       "         1.40013872e-04, 3.01174063e-04, 1.36970286e-03, 1.25211896e-04,\n",
       "         4.44196572e-04, 1.11806288e-03, 4.60482610e-04, 2.73434888e-03,\n",
       "         6.20812934e-04, 9.56979289e-04, 1.29243606e-04, 5.78077976e-04,\n",
       "         1.50072563e-03, 2.82143563e-04, 2.80001841e-04, 2.10680897e-04,\n",
       "         9.32253723e-04, 4.99862013e-04, 8.71362499e-05, 4.05673054e-04,\n",
       "         1.32435956e-03, 3.78241930e-05, 6.77011500e-04, 2.94738589e-03,\n",
       "         1.28477020e-03, 2.68346485e-04, 7.64307100e-04, 1.09738531e-03,\n",
       "         5.51565608e-04, 1.45554810e-03, 1.72398868e-04, 3.31913354e-04,\n",
       "         3.17119382e-04, 9.13303171e-04, 2.80476088e-04, 2.64228228e-03,\n",
       "         1.02638514e-04, 4.19338139e-05, 3.78093706e-03, 7.89808182e-05,\n",
       "         3.39972787e-04, 1.29549531e-04, 1.39622181e-03, 9.27117944e-05,\n",
       "         6.48569025e-04, 2.09247619e-02, 1.43506739e-04, 1.11404435e-04,\n",
       "         2.34297026e-04, 2.56342348e-03, 2.32138415e-03, 2.19653783e-04,\n",
       "         4.33391921e-04, 9.83784441e-04, 5.99901774e-04, 5.10815007e-04,\n",
       "         4.99588344e-03, 1.46188820e-03, 3.97131604e-04, 3.69444198e-04,\n",
       "         1.15194847e-03, 5.09206613e-04, 1.63213420e-03, 1.29028776e-04,\n",
       "         5.96658560e-04, 2.96716782e-04, 7.32310582e-05, 2.28460785e-03,\n",
       "         2.53909826e-03, 3.29270086e-04, 1.70602711e-04, 2.14876054e-04,\n",
       "         1.04073295e-03, 3.11791402e-04, 8.02834038e-05, 2.04042895e-04,\n",
       "         1.06466543e-02, 1.26046746e-03, 2.15279826e-04, 4.32777742e-05,\n",
       "         6.93189038e-04, 4.52498170e-05, 1.72333690e-04, 2.96128215e-04,\n",
       "         7.88061356e-04, 2.05587642e-03, 6.54294272e-04, 1.23141147e-03,\n",
       "         1.11301020e-02, 6.02283794e-03, 1.99477002e-03, 6.19687838e-04,\n",
       "         3.25768546e-04, 3.40607512e-05, 3.52805248e-04, 1.06384384e-03,\n",
       "         2.37977039e-03, 2.37825583e-03, 3.32591264e-03, 3.98588629e-04,\n",
       "         1.02372906e-04, 1.31014164e-03, 4.38571500e-04, 4.89493366e-04,\n",
       "         6.26757648e-03, 1.06960628e-03, 2.17437249e-04, 2.31609959e-03,\n",
       "         1.90753097e-04, 2.43252536e-04, 1.08896587e-04, 4.87216166e-04,\n",
       "         9.46475848e-05, 5.05234930e-04, 2.97398539e-04, 1.26685516e-03,\n",
       "         3.68891255e-04, 4.84328571e-04, 9.22082283e-04, 2.24830786e-04,\n",
       "         5.86957030e-04, 1.48704241e-03, 1.42444973e-03, 4.10440698e-04,\n",
       "         2.01076944e-03, 2.02928041e-03, 3.57125257e-03, 3.83322389e-04,\n",
       "         1.20114791e-03, 2.55176029e-03, 2.43813527e-04, 1.07004761e-03,\n",
       "         3.88781133e-04, 1.59246847e-04, 3.61758342e-04, 1.40701814e-04,\n",
       "         2.48368643e-03, 2.99664983e-03, 5.33396196e-05, 6.87190040e-04,\n",
       "         9.85464547e-04, 5.20431960e-04, 1.08742010e-04, 3.77894007e-03,\n",
       "         5.81220491e-04, 3.05714738e-03, 5.43978764e-04, 8.54748476e-04,\n",
       "         2.60490854e-03, 1.21063564e-03, 9.24380671e-04, 1.38039759e-04,\n",
       "         1.61186021e-04, 6.95144292e-04, 1.92233711e-03, 6.91958485e-05,\n",
       "         4.42906865e-04, 1.29271473e-04, 5.78257837e-04, 1.88986515e-03,\n",
       "         2.12400639e-03, 6.25908375e-04, 4.87505808e-04, 6.15340716e-04,\n",
       "         1.30624321e-04, 1.97118474e-03, 1.87098660e-04, 4.33569221e-04,\n",
       "         1.16180570e-03, 3.88091546e-03, 1.20558580e-02, 3.87123233e-04,\n",
       "         3.19521117e-04, 7.48483115e-04, 1.36050733e-03, 1.09337608e-03,\n",
       "         4.17595584e-05, 5.02250390e-04, 1.79181865e-04, 5.41898014e-04,\n",
       "         2.74438714e-03, 5.24429197e-04, 2.27447410e-04, 2.57074775e-04,\n",
       "         2.50418205e-04, 9.73008689e-04, 8.05157877e-04, 8.43661604e-04,\n",
       "         1.88970077e-03, 3.69512034e-03, 1.64342317e-04, 7.16638402e-04,\n",
       "         1.32021424e-03, 5.17030930e-05, 8.15943233e-04, 4.00662429e-05,\n",
       "         7.60406692e-05, 1.26150277e-04, 1.04633626e-04, 7.49924802e-04,\n",
       "         2.99212290e-04, 1.52179418e-04, 4.97553207e-04, 1.33388414e-04,\n",
       "         2.07004067e-03, 4.41523152e-05, 3.68151494e-04, 1.55784830e-03,\n",
       "         3.91814858e-04, 2.95811828e-04, 2.87795468e-04, 1.99647373e-04,\n",
       "         5.07651072e-04, 6.25480956e-04, 1.94061035e-03, 1.31602690e-04,\n",
       "         1.37271162e-03, 3.76372249e-04, 6.24393462e-04, 1.68969753e-04,\n",
       "         2.50215130e-03, 5.04964357e-03, 1.13911158e-03, 1.46410806e-04,\n",
       "         5.30749967e-04, 1.43093010e-03, 1.00631663e-03, 7.90581398e-04,\n",
       "         6.50285219e-04, 9.57568700e-05, 5.58814208e-05, 1.65011757e-03,\n",
       "         4.15300419e-05, 1.43690180e-04, 2.81235843e-04, 1.31472794e-03,\n",
       "         6.88866203e-05, 8.67824350e-03, 2.66472984e-04, 1.10099354e-04,\n",
       "         6.89042208e-05, 3.90804271e-05, 9.15050477e-05, 1.45186306e-04,\n",
       "         5.11863828e-03, 2.04339085e-04, 2.16644301e-04, 1.79894560e-04,\n",
       "         4.49121813e-04, 1.56831433e-04, 6.98715303e-05, 3.21433559e-04,\n",
       "         2.55080406e-03, 2.22842893e-04, 1.11663714e-04, 1.94717388e-04,\n",
       "         2.42748356e-04, 1.58152616e-04, 8.11242207e-04, 1.67223089e-03,\n",
       "         3.86509299e-03, 8.23207025e-04, 1.07090636e-04, 2.31710437e-04,\n",
       "         1.32088418e-04, 1.50895590e-04, 3.41007486e-04, 4.64796496e-04,\n",
       "         4.78642993e-03, 2.11363286e-03, 1.10858981e-03, 8.72885401e-04,\n",
       "         2.07152474e-03, 3.26386164e-03, 1.95998768e-03, 1.88045716e-03,\n",
       "         8.77282408e-04, 3.03837704e-03, 1.37903215e-03, 2.38986031e-04,\n",
       "         1.49007677e-03, 1.00466632e-03, 5.93128498e-04, 5.28169097e-04,\n",
       "         3.43369273e-03, 5.32328268e-04, 1.98019156e-03, 1.55928044e-03,\n",
       "         8.87202696e-05, 6.25879678e-04, 3.84810934e-04, 2.97097780e-04,\n",
       "         1.00123347e-04, 1.01511687e-04, 1.46852899e-03, 6.40653714e-04,\n",
       "         2.10668150e-04, 5.77727938e-03, 2.80872593e-03, 4.13019501e-04,\n",
       "         9.23804691e-05, 1.15678075e-03, 6.94360060e-05, 2.79973523e-04,\n",
       "         5.17113251e-04, 8.92998767e-04, 2.67657917e-04, 7.80221832e-04,\n",
       "         3.35384480e-04, 3.21858126e-04, 2.50277953e-04, 5.25956159e-04,\n",
       "         2.04676500e-04, 1.67287246e-04, 4.04860242e-04, 1.23195161e-04,\n",
       "         2.94236350e-04, 1.52597539e-04, 9.91785200e-04, 2.57686072e-04,\n",
       "         1.49347907e-04, 1.40836128e-04, 6.87819484e-05, 2.08247846e-04,\n",
       "         7.60668947e-04, 8.11506252e-05, 1.92535968e-04, 2.79603963e-04,\n",
       "         2.25066455e-04, 1.17862408e-04, 3.92348826e-04, 8.51540390e-05,\n",
       "         2.98313214e-04, 1.64983023e-04, 1.60902971e-04, 1.92425650e-04,\n",
       "         1.90406397e-04, 1.24841332e-02, 8.90102383e-05, 9.34871641e-05,\n",
       "         2.22875620e-04, 1.34255865e-03, 5.24465460e-04, 5.18391724e-04,\n",
       "         6.11039344e-04, 4.96810069e-04, 4.13210568e-04, 1.36736408e-03,\n",
       "         1.87695478e-04, 4.48917308e-05, 4.42581717e-04, 1.97724250e-04,\n",
       "         1.88073638e-04, 3.19305435e-03, 2.49619421e-04, 1.28705549e-04,\n",
       "         4.81516268e-04, 2.20364760e-04, 3.43071617e-04, 1.17707852e-04,\n",
       "         1.40186152e-04, 1.64242127e-04, 4.92010076e-05, 2.85760150e-04,\n",
       "         4.01628989e-04, 1.55756003e-04, 3.83113875e-05, 6.00574240e-05,\n",
       "         1.40269476e-04, 2.43612121e-05, 1.26941843e-04, 1.91909494e-04,\n",
       "         1.49514133e-04, 1.19101023e-04, 1.75936570e-04, 2.12957598e-02]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend the API using custom layers\n",
    "- `tf.keras` includes a wide range of built-in layers.\n",
    "    - Convolutional layers: `Conv1D`, `Conv2D`, `Conv3D`, `Conv2DTranspose`\n",
    "    - Pooling layers: `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`, `AveragePooling1D`\n",
    "    - RNN layers: `GRU`, `LSTM`, `ConvLSTM2D`\n",
    "    - `BatchNormalization`, `Dropout`, `Embedding`, etc.\n",
    "- But you can also extend the API by creating your own layers.\n",
    "- All layers subclass the `Layer` class and implement the following.\n",
    "    - **`build` method**: creates the weights of the layer (you can also create weights in `__init__()`)\n",
    "    - **`call` method**: specifies the computation done by the layer\n",
    "- The following is a basic implementation of `tf.keras.layers.Dense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape = (input_shape[-1], self.units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape = (self.units,),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(4,))\n",
    "outputs = CustomDense(10)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model_6',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 4),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_9'},\n",
       "   'name': 'input_9',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'CustomDense',\n",
       "   'config': {'name': 'custom_dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 10},\n",
       "   'name': 'custom_dense',\n",
       "   'inbound_nodes': [[['input_9', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_9', 0, 0]],\n",
       " 'output_layers': [['custom_dense', 0, 0]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = model.get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.Model.from_config(config, custom_objects={'CustomDense': CustomDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use the functional API\n",
    "- In general, the functional API is higher-level, easier and safer, and has a number of features that subclassed models do not support.\n",
    "- However, model subclassing provides greater flexibility when building models that are not easily expressible as directed acyclic graphs of layers. \n",
    "    - For example, you could not implement a Tree-RNN with the functional API and would have to subclass Model directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix-and-match API styles\n",
    "- Choosing between the functional API or Model subclassing isn't a binary decision that restricts you into one category of models. \n",
    "- All models in the `tf.keras` API can interact with each other, whether they're Sequential models, functional models, or subclassed models that are written from scratch.\n",
    "- You can always use a functional model or Sequential model as part of a subclassed model or layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "\n",
    "# Define a Functional model\n",
    "inputs = keras.Input(shape=(None, units))\n",
    "X = layers.GlobalAveragePooling1D()(inputs)\n",
    "outputs = layers.Dense(1)(X)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Define a subclassed model that includes the Functional model defined above\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation='tanh')\n",
    "        self.projection_2 = layers.Dense(units=units, activation='tanh')\n",
    "        self.classifier = model\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        \n",
    "        for t in range(inputs.shape[1]):\n",
    "            X = inputs[:, t, :]\n",
    "            h = self.projection_1(X)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "            \n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        print(features.shape)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = CustomRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18846, shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model(tf.zeros((1, timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use any subclassed layer or model in the functional API as long as it implements a `call` method that follows one of the following patterns.\n",
    "    - **`call(self, inputs, **kwargs)`**\n",
    "        - Where `inputs` is a tensor or nested structure of tensors (e.g. a list of tensors), and `**kwargs` are non-tensor arguments (non-inputs).\n",
    "    - **`call(self, inputs, training=None, **kwargs)`**\n",
    "        - Where `training` is a boolean indicating whether the layer should behave in training mode and inference mode.\n",
    "    - **`call(self, inputs, mask=None, **kwargs)`**\n",
    "        - Where `mask` is a boolean mask tensor (useful for RNNs, for instance).\n",
    "    - **`call(self, inputs, training=None, mask=None, **kwargs)`** \n",
    "        - You can have both masking and training-specific behavior at the same time.\n",
    "- Additionally, if you implement the get_config method on your custom Layer or model, the functional models you create will still be serializable and cloneable.\n",
    "- Here's a quick example of a custom RNN, written from scratch, being used in a functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.classifier = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that you can specify a static batch size for the inputs with the `batch_size` argument because the inner computation of `CustomRNN` requires a static batch size (when you create the `state` zero tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "X = layers.Conv1D(32,3)(inputs)\n",
    "outputs = CustomRNN()(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
