{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\n",
    "- Schematically, a RNN layer uses a `for` loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has been so far.\n",
    "- The Keras RNN API is designed with a focus on:\n",
    "    - Ease of use\n",
    "        - The built-in `keras.layers.RNN`, `keras.layers.LSTM`, and `keras.layers.GRU` layers enable you to quickly build recurrent models without having to make difficult configuration choices.\n",
    "    - Ease of customization\n",
    "        - You can also define your own RNN cell layer (the inner part of the `for` loop) with custom behavior, and use it with the generic `keras.layers.RNN` layer (the `for` loop itself).\n",
    "        - This allows you to quickly prototype different research ideas in a flexible way with minimal code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in RNN layers: a simple example\n",
    "- Here is a simple example of a `Sequential` model that processes sequences of integers, emdes each integer into a 64-dimensional vector, and then proceses the sequence of vectors using a `LSTM` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# Add an Embedding layer expecting vocab of size 1000\n",
    "# Output embedding dimension of size 64\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs and states\n",
    "- By default, the output of a RNN layer contain a single vector per sample. \n",
    "    - This vector is the RNN cell output corresponding to the last timestep, containing information about the entire input sequence. \n",
    "        - The shape of this output is `(batch_size, units)` where units corresponds to the units argument passed to the layer's constructor.\n",
    "    - A RNN layer can also return the entire sequence of outputs for each sample (one vector per timestep per sample), if you set `return_sequences=True`. \n",
    "        - The shape of this output is `(batch_size, timesteps, units)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         247296    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of the following GRU layer will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of the following SimpleRNN layer will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In addition, a RNN layer can return its final internal state(s). \n",
    "    - The returned states can be used to resume the RNN execution later, or to initialize another RNN. \n",
    "    - This setting is commonly used in the encoder-decoder sequence-to-sequence model, where the encoder final state is used as the initial state of the decoder.\n",
    "- To configure a RNN layer to return its internal state, set the `return_state=True` when creating the layer. \n",
    "    - Note that LSTM has 2 state tensors, but GRU only has one.\n",
    "- To configure the initial state of the layer, just call the layer with additional keyword argument `initial_state`. \n",
    "    - Note that the shape of the state needs to match the unit size of the layer, like in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "# Return states in addition to output\n",
    "output, state_h, state_c = layers.LSTM(64, return_state=True, name='encoder')(encoder_embedded)\n",
    "\n",
    "encoder_state = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "# Pass the 2 states to a new LSTM layer as the initial state\n",
    "decoder_output = layers.LSTM(64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
    "\n",
    "output = layers.Dense(10)(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN layers and RNN cells\n",
    "- In addition to the built-in RNN layers, the RNN API also provides cell-level APIs.\n",
    "    - Unlike RNN layers, which processes whole batches of input sequences, the RNN cell only processes a single timestep.\n",
    "- The cell is the inside of the `for` loop of a RNN layer.\n",
    "    - Wrapping a cell inside a `keras.layers.RNN` layer gives you a layer capable of processing batches of sequencs.\n",
    "    - E.g. `RNN(LSTMCell(10)`\n",
    "- There are three built-in RNN cells, each corresponding to the matching RNN layer.\n",
    "    - `keras.layers.SimpleRNNCell` corresponds to the `SimpleRNN` layer.\n",
    "    - `keras.layers.GRUCell` corresponds to the `GRU` layer.\n",
    "    - `keras.layers.LSTMCell` corresponds to the `LSTM` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-batch statefulness\n",
    "- When processing very long sequences (possibly infinite), you may want to use the pattern of **cross-batch statefulness**.\n",
    "- Normally, the internal state of a RNN layer is reset every time it sees a new batch (i.e. every sample seen by the layer is assume to be independent from the past). \n",
    "    - The layer will only maintain a state while processing a given sample.\n",
    "- If you have very long sequences though, it is useful to **break them into shorter sequences, and to feed these shorter sequences sequentially into a RNN layer without resetting the layer's state**. \n",
    "    - That way, the layer can retain information about the entirety of the sequence, even though it's only seeing one sub-sequence at a time.\n",
    "- You can do this by setting `stateful=True` in the constructor.\n",
    "- When you want to clear the state, you can use `layer.reset_states()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_states() will reset the cached state to the original initial_state.\n",
    "# If no initial_state was provided, zero-states will be used by default.\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN State Reuse\n",
    "- The recorded states of the RNN layer are not included in the `layer.weights()`. \n",
    "- If you would like to reuse the state from a RNN layer, you can retrieve the states value by **`layer.states`** and use it as the initial state for a new layer via the Keras functional API like `new_layer(inputs, initial_state=layer.states)`, or model subclassing.\n",
    "- Please also note that sequential model might not be used in this case since it only supports layers with single input and output, the extra input of initial state makes it impossible to use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_state = lstm_layer.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lstm_layer = layers.LSTM(64)\n",
    "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNNs\n",
    "- For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. \n",
    "- For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
    "- Keras provides an easy API for you to build such bidirectional RNNs: the `keras.layers.Bidirectional` wrapper.\n",
    "    - Under the hood, `Bidirectional` will copy the RNN layer passed in, and flip the `go_backwards` field of the newly copied layer, so that it will process the inputs in reverse order.\n",
    "    - The output of the `Bidirectional` RNN will be, by default, the sum of the forward and backward layer output.\n",
    "        - If you need a different merging behavior, e.g. concatenation, change the `merge_mode` parameter in the `Bidirectional` wrapper constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
    ")\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance optimization and CuDNN kernels\n",
    "- In TensorFlow 2.0, the **built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default** when a GPU is available. \n",
    "    - With this change, the prior `keras.layers.CuDNNLSTM/CuDNNGRU` layers have been deprecated, and you can build your model without worrying about the hardware it will run on.\n",
    "- However, a layer will not be able to use the CuDNN kernel if you change the defualts of the built-in LSTM or GRU layers, such as the following.\n",
    "    - Changing the activation function from `tanh` to something else\n",
    "    - Changing the `recurrent_activation` function from `sigmoid` to something else\n",
    "    - Using `recurrent_dropout` > 0\n",
    "    - Setting `unroll` to `True`, which forces LSTM/GRU to decompose the inner `tf.while_loop` into an unrolled for loop\n",
    "    - Setting `use_bias` to `False`\n",
    "    - Using masking when the input data is not strictly right padded (if the mask corresponds to strictly right padded data, CuDNN can still be used. This is the most common case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CuDNN kernels when available\n",
    "- Let's build a simple LSTM model to demonstrate the performance difference.\n",
    "- We'll use sequences of sequence of rows of MNIST digits (treating each row of pixels as a timestep) as inputs, and we'll predict the digits' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Each MNIST image batch is a tensor of shape (batchbatch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10 # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel, while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN\n",
    "        lstm_layer = layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not leverage CuDNN\n",
    "        lstm_layer = layers.RNN(\n",
    "            layers.LSTMCell(units), \n",
    "            input_shape=(None, input_dim)\n",
    "        )\n",
    "        \n",
    "    model = keras.models.Sequential([\n",
    "        lstm_layer,\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(output_size)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "sample, sample_label = X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's create a model instance and train it.\n",
    "- We choose `SparseCategoricalCrossentropy` as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 68s 1ms/sample - loss: 0.9511 - accuracy: 0.7014 - val_loss: 0.5794 - val_accuracy: 0.8083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbba7cdb4d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "         batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's compare to a model that does not use the CuDNN kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.3739 - accuracy: 0.8880 - val_loss: 0.5675 - val_accuracy: 0.8139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbba7c6d850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
    "noncudnn_model.set_weights(model.get_weights())\n",
    "noncudnn_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "noncudnn_model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "         batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When running on a machine with a NVIDIA GPU and CuDNN installed, the model built with CuDNN is much faster to train compared to the model that use the regular TensorFlow kernel.\n",
    "- The same CuDNN-enabled model can also be use to run inference in a CPU-only environment. \n",
    "    - The model will run on CPU by default if no GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs with list/dict inputs or nested inputs\n",
    "- Nested structures allow implementers to include more information within a single timestep. \n",
    "    - For example, a video frame could have audio and video input at the same time. \n",
    "        - The data shape in this case could be:`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`.\n",
    "    - In another example, handwriting data could have both coordinates x and y for the current position of the pen, as well as pressure information. \n",
    "        - So the data representation could be:`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`.\n",
    "- The following code provides an example of how to build a custom RNN cell that accepts such structured inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedCell(keras.layers.Layer):\n",
    "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
    "        self.unit_1 = unit_1\n",
    "        self.unit_2 = unit_2\n",
    "        self.unit_3 = unit_3\n",
    "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        super(NestedCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
    "        i1 = input_shapes[0][1]\n",
    "        i2 = input_shapes[1][1]\n",
    "        i3 = input_shapes[1][2]\n",
    "\n",
    "        self.kernel_1 = self.add_weight(\n",
    "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
    "        )\n",
    "        self.kernel_2_3 = self.add_weight(\n",
    "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
    "            initializer=\"uniform\",\n",
    "            name=\"kernel_2_3\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
    "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
    "        input_1, input_2 = tf.nest.flatten(inputs)\n",
    "        s1, s2 = states\n",
    "\n",
    "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
    "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
    "        state_1 = s1 + output_1\n",
    "        state_2_3 = s2 + output_2_3\n",
    "\n",
    "        output = (output_1, output_2_3)\n",
    "        new_states = (state_1, state_2_3)\n",
    "\n",
    "        return output, new_states\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's build a Keras model that uses a `keras.layers.RNN` layer and the custom cell defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "\n",
    "i1 = 32\n",
    "i2 = 64\n",
    "i3 = 32\n",
    "batch_size = 64\n",
    "num_batches = 10\n",
    "timestep = 50\n",
    "\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = keras.layers.RNN(cell)\n",
    "\n",
    "input_1 = keras.Input((None, i1))\n",
    "input_2 = keras.Input((None, i2, i3))\n",
    "\n",
    "outputs = rnn((input_1, input_2))\n",
    "\n",
    "model = keras.models.Model([input_1, input_2], outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's train the model with randomly generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples\n",
      "640/640 [==============================] - 7s 11ms/sample - loss: 0.7538 - rnn_1_loss: 0.2654 - rnn_1_1_loss: 0.4884 - rnn_1_accuracy: 0.1266 - rnn_1_1_accuracy: 0.0318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbb5cb0a090>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
    "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
    "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
